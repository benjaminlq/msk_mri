{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWTwpVcAhEQl"
      },
      "source": [
        "# **AI Chatbots for Imaging Recommendations Aligned with ACR Guidelines**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lTvJntMww5Ur"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index==0.5.0 -q\n",
        "!pip install gradio -q\n",
        "!pip install PyPDF2 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "kFaXpZjieSV_",
        "outputId": "0722a3a7-3aeb-4e84-bdef-ad057de66eed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The folder path either does not exist or does not contain PDF files.\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/gradio/routes.py\", line 534, in predict\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/gradio/blocks.py\", line 1185, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/gradio/utils.py\", line 661, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/tmp/ipykernel_2549/3717533942.py\", line 65, in get_combined_chatbot_response\n",
            "    index = GPTVectorStoreIndex.load_from_disk('index_simple35.json')\n",
            "AttributeError: type object 'VectorStoreIndex' has no attribute 'load_from_disk'\n",
            "Traceback (most recent call last):\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/gradio/routes.py\", line 534, in predict\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/gradio/blocks.py\", line 1185, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/gradio/utils.py\", line 661, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/tmp/ipykernel_2549/3717533942.py\", line 65, in get_combined_chatbot_response\n",
            "    index = GPTVectorStoreIndex.load_from_disk('index_simple35.json')\n",
            "AttributeError: type object 'VectorStoreIndex' has no attribute 'load_from_disk'\n",
            "Traceback (most recent call last):\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/gradio/routes.py\", line 534, in predict\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/gradio/blocks.py\", line 1185, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/mnt/c/Users/QUAN/Desktop/lbp_mri/venv/lib/python3.10/site-packages/gradio/utils.py\", line 661, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/tmp/ipykernel_2549/3717533942.py\", line 65, in get_combined_chatbot_response\n",
            "    index = GPTVectorStoreIndex.load_from_disk('index_simple35.json')\n",
            "AttributeError: type object 'VectorStoreIndex' has no attribute 'load_from_disk'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import sys\n",
        "import glob\n",
        "import gradio as gr\n",
        "import openai\n",
        "from llama_index import (\n",
        "    VectorStoreIndex,\n",
        "    LLMPredictor,\n",
        "    SimpleDirectoryReader,\n",
        "    ServiceContext,\n",
        "    load_index_from_storage\n",
        ")\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from config import DATA_DIR, MAIN_DIR\n",
        "\n",
        "# Set the OpenAI API key. If unsure about obtaining the API key, refer to https://platform.openai.com/account/api-keys for more information.\n",
        "# For estimating costs associated with index creation and chatbot usage, please visit: https://openai.com/pricing\n",
        "with open(os.path.join(MAIN_DIR, \"auth\", \"api_keys.json\")) as f:\n",
        "    api_keys = json.load(f)\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_keys[\"OPENAI_API_KEY\"]\n",
        "\n",
        "\n",
        "# Set the folder path for ACR data and the rebuild index flag. This script doesn't include\n",
        "# importing ACR guidelines or a predefined index due to license restrictions on ACR guidelines.\n",
        "# For more information, refer to the guidelines on the ACR website.\n",
        "\n",
        "FOLDER_PATH = os.path.join(DATA_DIR, \"emb_store\", \"simple\", \"openai_512_20\")\n",
        "REBUILD_INDEX = False\n",
        "\n",
        "def setup_index(folder_path, rebuild_index):\n",
        "    index_file_name = 'index_simple35.json'\n",
        "    \n",
        "    # Check if the folder path exists and contains PDF files\n",
        "    if not os.path.exists(folder_path) or not glob.glob(f\"{folder_path}/*.pdf\"):\n",
        "        print(\"The folder path either does not exist or does not contain PDF files.\")\n",
        "        return\n",
        "\n",
        "    # Rebuild the index if rebuild_index is True or the index file does not exist\n",
        "    if rebuild_index or not os.path.isfile(index_file_name):\n",
        "        # Load documents from the folder path\n",
        "        documents = SimpleDirectoryReader(folder_path).load_data()\n",
        "        \n",
        "        # Initialize the LLMPredictor with the ChatOpenAI model\n",
        "        llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", max_tokens=512, request_timeout=120))\n",
        "        \n",
        "        # Create a service context for the LLMPredictor\n",
        "        service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, chunk_size_limit=512)\n",
        "        \n",
        "        # Create an index from the documents and save it to disk\n",
        "        index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
        "        index.save_to_disk(index_file_name)\n",
        "\n",
        "def get_combined_chatbot_response(input_text):\n",
        "    # Format the input text\n",
        "    input_text = f'Case: {input_text} Question: Is imaging for this Usually Appropriate and if yes, state precisely only what imaging modality is the most Appropriate and if contrast agent is needed, do not mention \"May Be Appropriate\" or \"Usually Not Appropriate\".)'\n",
        "    \n",
        "    # Initialize the LLMPredictor with the ChatOpenAI model used in accGPT\n",
        "    llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", max_tokens=512, request_timeout=120))\n",
        "    \n",
        "    # Create a service context for the LLMPredictor\n",
        "    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, chunk_size_limit=512)\n",
        "\n",
        "    # Load the index from disk\n",
        "    from llama_index.vector_stores import SimpleVectorStore\n",
        "    from llama_index.storage import StorageContext\n",
        "    vector_store = SimpleVectorStore.from_persist_dir(FOLDER_PATH)\n",
        "    storage_context = StorageContext.from_defaults(vector_store=vector_store, persist_dir=FOLDER_PATH)\n",
        "    index = load_index_from_storage(storage_context=storage_context, index_id=\"msk-mri\")\n",
        "    \n",
        "    # Define the messages to be sent to the models without index\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are ChatGPT, a large language model trained by OpenAI. Answer as concisely as possible.\"},\n",
        "        {\"role\": \"user\", \"content\": input_text},\n",
        "    ]\n",
        "\n",
        "    # accGPT approach: Query the index and get the response from Top 3 Text nodes using GPT-3.5-Turbo \n",
        "    response = index.query(input_text, response_mode=\"compact\", service_context=service_context, similarity_top_k=3)\n",
        "    output_accGPT = response.response.replace('\\n', '\\\\n')\n",
        "\n",
        "    # Get the response from GPT-3.5-Turbo\n",
        "    response35 = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=messages, timeout=120)\n",
        "    output35 = response35.choices[0].message['content'].replace('\\n', '\\\\n')\n",
        "    \n",
        "    # Get the response from GPT-4\n",
        "    response4 = openai.ChatCompletion.create(model=\"gpt-4\", messages=messages, timeout=120)\n",
        "    output4 = response4.choices[0].message['content'].replace('\\n', '\\\\n')\n",
        "    \n",
        "    # Combine the responses from all models\n",
        "    answer = f\"accGPT: {output_accGPT}\\n\\nGPT 3.5-Turbo: {output35}\\n\\nGPT 4: {output4}\"\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "def launch_interface(chatbot_function):\n",
        "    iface = gr.Interface(\n",
        "        fn=get_combined_chatbot_response,\n",
        "        inputs=[gr.Textbox(lines=7, label=\"Enter your case\")],\n",
        "        outputs=gr.Textbox(lines=7, label=\"Imaging Recommendations\"),\n",
        "        title=\"AI Chatbots for Imaging Recommendations Aligned with ACR Guidelines\"\n",
        "    )\n",
        "\n",
        "    # Launch the interface\n",
        "    iface.launch(share=True, debug=False)\n",
        "\n",
        "def main():\n",
        "    setup_index(FOLDER_PATH, REBUILD_INDEX)\n",
        "    launch_interface(get_combined_chatbot_response)\n",
        "\n",
        "main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
