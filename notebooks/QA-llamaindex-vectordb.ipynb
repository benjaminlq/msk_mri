{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os, json\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "import tiktoken\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "from config import MAIN_DIR, GUIDELINES\n",
    "from copy import deepcopy\n",
    "from utils import load_vectorindex\n",
    "from datetime import datetime\n",
    "from textdistance import levenshtein\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Union, Optional, List, Literal, Callable, Sequence, Tuple\n",
    "from utils import count_tokens\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate as LCChatPromptTemplate\n",
    "from langchain.prompts import HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "from llama_index import (ServiceContext, QueryBundle, SimpleDirectoryReader, get_response_synthesizer)\n",
    "from llama_index.callbacks import CallbackManager, TokenCountingHandler\n",
    "from llama_index.callbacks.schema import CBEventType, EventPayload\n",
    "from llama_index.embeddings import OpenAIEmbedding\n",
    "from llama_index.indices.base_retriever import BaseRetriever\n",
    "from llama_index.indices.postprocessor import MetadataReplacementPostProcessor, LongContextReorder\n",
    "from llama_index.postprocessor.types import BaseNodePostprocessor\n",
    "from llama_index.indices.query.base import BaseQueryEngine\n",
    "from llama_index.indices.query.schema import QueryBundle, QueryType\n",
    "from llama_index.llms import ChatMessage, MessageRole, OpenAI\n",
    "from llama_index.prompts import ChatPromptTemplate, BasePromptTemplate\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.response.schema import Response, RESPONSE_TYPE\n",
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.schema import Document, NodeWithScore, TextNode\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "from custom import CustomCombinedRetriever, CustomRetrieverQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(MAIN_DIR, \"data\")\n",
    "ARTIFACT_DIR = os.path.join(MAIN_DIR, \"artifacts\")\n",
    "EMB_DIR = os.path.join(DATA_DIR, \"emb_store\")\n",
    "DOCUMENT_DIR = os.path.join(MAIN_DIR, \"data\", \"document_sources\")\n",
    "EXCLUDE_DICT = os.path.join(DATA_DIR, \"exclude_pages.json\")\n",
    "\n",
    "with open(os.path.join(MAIN_DIR, \"auth\", \"api_keys.json\"), \"r\") as f:\n",
    "    api_keys = json.load(f)\n",
    "    \n",
    "os.environ[\"OPENAI_API_KEY\"] = api_keys[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_guidelines = \"\\n\".join([\"- \" + guideline for guideline in GUIDELINES])\n",
    "\n",
    "refine_template = \"\"\"You are a radiologist expert. Do not make up additional information.\n",
    "=========\n",
    "TASK: You are given a PATIENT PROFILE. You need to perform the following information referencing from the PATIENT PROFILE:\n",
    "1. Extract relevant information for recommendation of imaging procedure, including age, symptomps, previous diagnosis, stage of diagnosis (INITIAL IMAGING OR NEXT STUDY) and suspected conditions, if any.\n",
    "Only return information given inside the PROFILE, do not make up other information.\n",
    "2. Return one or more guidelines from the following list of guidelines potentially relevant to the recommendations of imaging procedure given patient profile. If there are no relevant guidelines, return empty list.\n",
    "{}\n",
    "=========\n",
    "OUTPUT INSTRUCTION:\n",
    "Output your answer as follow:\n",
    "1. Relevant information:\n",
    "2. Relevant guidelines: List of guidelines. Match the exact text given in the list. If no relevant guidelines, return [].\n",
    "=========\n",
    "\"\"\".format(all_guidelines)\n",
    "\n",
    "human_template = \"PATIENT PROFILE: {query_str}\"\n",
    "\n",
    "REFINE_TEMPLATE = LCChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(refine_template),\n",
    "        HumanMessagePromptTemplate.from_template(human_template)\n",
    "    ]\n",
    ")\n",
    "\n",
    "refine_chain = LLMChain(\n",
    "    prompt=REFINE_TEMPLATE,\n",
    "    llm=ChatOpenAI(model=\"gpt-4-1106-preview\", temperature=0, max_tokens=512)\n",
    "    )\n",
    "\n",
    "extract_template = \"\"\"TASK: Extract the following information from the provided text query.\n",
    "1. Appropropriateness of the scan ordered.\n",
    "2. Most Appropriate Imaging Modality\n",
    "===============\n",
    "FORMAT INSTRUCTIONS: Your output should contains the following:\n",
    "Appropriateness: Can be one of [USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE, INSUFFICIENT INFORMATION]\n",
    "Recommendation: The most appropriate imaging modality. If no appropriate imaging modality, return nothing.\n",
    "===============\n",
    "TEXT QUERY: {query}\n",
    "\"\"\"\n",
    "\n",
    "from langchain.prompts import PromptTemplate as LCPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI as LCChatOpenAI\n",
    "\n",
    "FIX_PROMPT = LCPromptTemplate.from_template(extract_template)\n",
    "\n",
    "fixing_chain = LLMChain(\n",
    "    llm=LCChatOpenAI(model_name=\"gpt-3.5-turbo-1106\", temperature=0, max_tokens=512),\n",
    "    prompt=FIX_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_pages(\n",
    "    doc_list: List[Document],\n",
    "    exclude_info: Dict[str, List]\n",
    ") -> List[Document]:\n",
    "    filtered_list = []\n",
    "    for doc in doc_list:\n",
    "        file_name = doc.metadata[\"file_name\"]\n",
    "        page = doc.metadata[\"page_label\"]\n",
    "        if file_name not in exclude_info.keys():\n",
    "            filtered_list.append(doc)\n",
    "            continue\n",
    "        if int(page) not in exclude_info[file_name]:\n",
    "            filtered_list.append(doc)\n",
    "\n",
    "    return filtered_list\n",
    "\n",
    "def convert_prompt_to_string(prompt) -> str:\n",
    "    if isinstance(prompt, BasePromptTemplate):\n",
    "        return prompt.format(**{v: v for v in prompt.template_vars})\n",
    "    if isinstance(prompt, Union[LCPromptTemplate, LCChatPromptTemplate]):\n",
    "        return prompt.format(**{v: v for v in prompt.input_variables})\n",
    "\n",
    "def generate_query(profile: str, scan: str):\n",
    "    return \"Patient Profile: {}\\nScan ordered: {}\".format(profile, scan)\n",
    "\n",
    "def convert_doc_to_dict(doc: Union[Document, NodeWithScore, Dict]) -> Dict:\n",
    "    if isinstance(doc, NodeWithScore):\n",
    "        json_doc = {\n",
    "            \"page_content\": doc.text,\n",
    "            \"metadata\": doc.metadata,\n",
    "            \"score\": doc.score\n",
    "            } \n",
    "    elif isinstance(doc, Document):\n",
    "        json_doc = {\n",
    "            \"page_content\": doc.text,\n",
    "            \"metadata\": doc.metadata,\n",
    "            \"score\": \"\"\n",
    "            }\n",
    "    elif isinstance(doc, Dict):\n",
    "        json_doc = {\n",
    "            \"page_content\": doc[\"text\"],\n",
    "            \"metadata\": doc[\"metadata\"],\n",
    "            \"score\": \"None\"\n",
    "        }\n",
    "    return json_doc\n",
    "\n",
    "def get_experiment_logs(description: str, log_folder: str):\n",
    "    logger = logging.getLogger(description)\n",
    "\n",
    "    stream_handler = logging.StreamHandler(sys.stdout)\n",
    "\n",
    "    if not os.path.exists(log_folder):\n",
    "        os.makedirs(log_folder, exist_ok=True)\n",
    "\n",
    "    file_handler = logging.FileHandler(filename=os.path.join(log_folder, \"logfile.log\"))\n",
    "\n",
    "    formatter = logging.Formatter(\"%(asctime)s:%(levelname)s: %(message)s\")\n",
    "    file_handler.setFormatter(formatter)\n",
    "    stream_handler.setFormatter(formatter)\n",
    "\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.addHandler(stream_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "def remove_final_sentence(\n",
    "    text: str,\n",
    "    return_final_sentence: bool = False\n",
    "):\n",
    "    text = text.strip()\n",
    "    if text.endswith(\".\"):\n",
    "        text = text[:-1]\n",
    "    sentence_list = text.split(\".\")\n",
    "    previous_text = \".\".join(sentence_list[:-1])\n",
    "    final_sentence = sentence_list[-1]\n",
    "    return (previous_text, final_sentence) if return_final_sentence else previous_text\n",
    "\n",
    "def query_wrapper(\n",
    "    template: str, \n",
    "    input_text: Union[str, Dict[str, str]]\n",
    ") -> str:\n",
    "    placeholders = re.findall(pattern = r\"{([A-Za-z0-9_-]+)}\", string=template)\n",
    "    if isinstance(input_text, str):\n",
    "        assert len(placeholders) == 1, \"Must Provide a single placeholder when input_text is string.\"\n",
    "        placeholder = placeholders[0]\n",
    "        return template.format(**{placeholder:input_text})\n",
    "    \n",
    "    assert len(input_text) == len(placeholders)\n",
    "    for key in input_text.keys():\n",
    "        assert key in placeholders, f\"{key} not present in template.\"\n",
    "    \n",
    "    return template.format(**input_text)\n",
    "\n",
    "def calculate_min_dist(\n",
    "    input_str: str,\n",
    "    text_list: List[str] = GUIDELINES,\n",
    "    return_nearest_text: bool = False\n",
    "):\n",
    "    min_dist = float(\"inf\")\n",
    "    nearest_text = None\n",
    "\n",
    "    for ref_text in text_list:\n",
    "        dist = levenshtein.distance(input_str, ref_text)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            nearest_text = ref_text\n",
    "    return (min_dist, nearest_text) if return_nearest_text else min_dist\n",
    "\n",
    "def setup_query_engine(\n",
    "    db_directory: str,\n",
    "    emb_store_type: Literal[\"simple, faiss\"] = \"simple\",\n",
    "    index_name: Optional[str] = None,\n",
    "    similarity_top_k: int = 4,\n",
    "    text_qa_template: Optional[BasePromptTemplate] = None,\n",
    "    synthesizer_llm: str = \"gpt-3.5-turbo-1106\",\n",
    "    emb_type: str = \"openai\",\n",
    "    synthesizer_temperature: int = 0,\n",
    "    synthesizer_max_tokens: int = 512,\n",
    "    response_mode: str = \"simple_summarize\",\n",
    "    node_postprocessors: Optional[List[BaseNodePostprocessor]] = None,\n",
    "    callback_manager: Optional[CallbackManager] = None,\n",
    ") ->  BaseQueryEngine:\n",
    "    \n",
    "    vector_index = load_vectorindex(db_directory, emb_store_type=emb_store_type, index_name=index_name)\n",
    "    \n",
    "    if emb_type == \"openai\":\n",
    "        embs = OpenAIEmbedding()\n",
    "\n",
    "    retriever = VectorIndexRetriever(\n",
    "        index=vector_index, similarity_top_k=similarity_top_k,\n",
    "        callback_manager=callback_manager\n",
    "    )\n",
    "\n",
    "    # Setup Synthesizer\n",
    "    service_context = ServiceContext.from_defaults(\n",
    "        llm=OpenAI(\n",
    "            temperature=synthesizer_temperature,\n",
    "            model=synthesizer_llm, max_tokens=synthesizer_max_tokens\n",
    "            ),\n",
    "        embed_model=embs, callback_manager=callback_manager\n",
    "    )\n",
    "\n",
    "    response_synthesizer = get_response_synthesizer(\n",
    "        service_context=service_context, response_mode=response_mode,\n",
    "        text_qa_template=text_qa_template\n",
    "    )\n",
    "    \n",
    "    # Setup QueryEngine\n",
    "    query_engine = RetrieverQueryEngine(\n",
    "        retriever=retriever, response_synthesizer=response_synthesizer,\n",
    "        node_postprocessors = node_postprocessors\n",
    "    )\n",
    "    \n",
    "    return query_engine\n",
    "\n",
    "def process_result_json(\n",
    "    testcase_df: pd.DataFrame, responses: List[Response], save_path: Optional[str] = None\n",
    ") -> Dict:\n",
    "    json_responses = []\n",
    "    queries = testcase_df[\"queries\"]\n",
    "    scan_orders = testcase_df[\"Scan Order\"]\n",
    "    \n",
    "    tk = tqdm(zip(queries, responses, scan_orders), total=len(responses))\n",
    "    for query, response, scan_order in tk:\n",
    "        testcase_info = {\n",
    "            \"question\": query,\n",
    "            \"result\": response.response,\n",
    "            \"source_documents\": [convert_doc_to_dict(doc) for doc in response.source_nodes]\n",
    "        }\n",
    "        answer_query = \"Scan Ordered: {}\\nAnswer: {}\".format(scan_order, testcase_info[\"result\"])\n",
    "        fixed_answer = fixing_chain(answer_query)\n",
    "        try:\n",
    "            appropriateness, recommendation = re.findall(\n",
    "            #  r\"^Appropriateness: ([0-9A-Za-z ]+)\\nRecommendation: ([0-9A-Za-z \\.]+)$\", fixed_answer[\"text\"])[0]\n",
    "                r\"^[^\\n]*Appropriateness: ([^\\n]+)\\n+[^\\n]*Recommendation: ([^\\n]+)$\", fixed_answer[\"text\"])[0]\n",
    "        except:\n",
    "            appropriateness, recommendation = \"\", \"\"\n",
    "        testcase_info[\"appropriateness\"] = appropriateness\n",
    "        testcase_info[\"recommendation\"] = recommendation\n",
    "\n",
    "        json_responses.append(testcase_info)\n",
    "        \n",
    "    if save_path:\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump(json_responses, f)\n",
    "    return json_responses\n",
    "\n",
    "def process_result_df(\n",
    "    testcase_df: pd.DataFrame, results: Union[List[Dict], List[Response]], save_path: Optional[str] = None\n",
    "):\n",
    "    if isinstance(results[0], Response):\n",
    "        results = process_result_json(testcase_df, results)\n",
    "    \n",
    "    result_df = deepcopy(testcase_df)\n",
    "    result_df[\"gpt_raw_answer\"] = [response[\"result\"] for response in results]\n",
    "    result_df[\"gpt_classification\"] = [response[\"appropriateness\"] for response in results]\n",
    "    result_df[\"gpt_classification\"] = result_df[\"gpt_classification\"].str.upper()\n",
    "    result_df[\"gpt_recommendation\"] = [response[\"recommendation\"] for response in results]\n",
    "    result_df[\"context\"] = [\n",
    "        \"\\n\\n\\n\\n\".join([\"Metadata: {}\\nScore: {}\\n\\nPage Content: {}\".format(\n",
    "            \"\\n\".join([f\"{k}: {v}\" for k, v in document[\"metadata\"].items()]),\n",
    "            document[\"score\"],  document[\"page_content\"])\n",
    "                         for document in response[\"source_documents\"]])\n",
    "        for response in results\n",
    "    ]\n",
    "\n",
    "    result_df = result_df.rename(columns = {\"Appropriateness Category\": \"human_gt\"})\n",
    "\n",
    "    result_df[\"human_gt\"] = result_df[\"human_gt\"].str.replace(r\"^UA$\", \"USUALLY APPROPRIATE\", regex=True)\n",
    "    result_df[\"human_gt\"] = result_df[\"human_gt\"].str.replace(r\"^UNA$\", \"USUALLY NOT APPROPRIATE\", regex=True)\n",
    "    result_df[\"human_gt\"] = result_df[\"human_gt\"].str.replace(r\"^MBA$\", \"MAY BE APPROPRIATE\", regex=True)\n",
    "    result_df[\"human_gt\"] = result_df[\"human_gt\"].str.replace(r\"^ICI$\", \"INSUFFICIENT INFORMATION\", regex=True)\n",
    "    \n",
    "    result_df[\"match\"] = (result_df[\"gpt_classification\"] == result_df[\"human_gt\"])\n",
    "\n",
    "    if save_path:\n",
    "        result_df.to_csv(save_path)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def count_tokens(\n",
    "    texts: Union[str, TextNode,NodeWithScore,List],\n",
    "    tokenizer: Callable = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "):\n",
    "    token_counter = 0\n",
    "    if not isinstance(texts, List):\n",
    "        texts = [texts]\n",
    "    for text in texts:\n",
    "        if isinstance(text, NodeWithScore):\n",
    "            text_str = text.node.text\n",
    "        elif isinstance(text, TextNode):\n",
    "            text_str = text.text\n",
    "        elif isinstance(text, str):\n",
    "            text_str = text\n",
    "        token_counter += len(tokenizer.encode(text_str))\n",
    "    return token_counter\n",
    "\n",
    "def extract_guidelines(\n",
    "    profile: str,\n",
    "    extract_chain: LLMChain\n",
    ") -> Tuple[str, List[str]]:\n",
    "    extracted_response = extract_chain(profile)[\"text\"]\n",
    "    if extracted_response.endswith(\".\"):\n",
    "        extracted_response = extracted_response[:-1]\n",
    "\n",
    "    pattern = r\"1. Relevant information:([\\S\\s]+)2. Relevant guidelines:([\\S\\s]*)\"\n",
    "\n",
    "    profile, guidelines_str = re.findall(pattern, extracted_response)[0]\n",
    "    guidelines_str = guidelines_str.replace(\"- \", \"\")\n",
    "    guidelines_str = guidelines_str.strip()\n",
    "    guidelines_str = guidelines_str.replace(\"\\n\", \", \")\n",
    "\n",
    "    if not guidelines_str:\n",
    "        relevant_guidelines = []\n",
    "    else:\n",
    "        regex_guidelines = re.findall(r\"([A-Za-z ]+)\", guidelines_str)\n",
    "        relevant_guidelines = []\n",
    "        for extracted_guideline in regex_guidelines:\n",
    "            extracted_guideline = extracted_guideline.lower()\n",
    "            min_dist, nearest_text = calculate_min_dist(extracted_guideline, GUIDELINES, True)\n",
    "            if min_dist <= 1:\n",
    "                extracted_guideline = nearest_text\n",
    "                relevant_guidelines.append(extracted_guideline)\n",
    "                \n",
    "    return profile, relevant_guidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_cases(\n",
    "    testcase_df: pd.DataFrame,\n",
    "    exp_args: Dict,\n",
    "    testcases: Sequence[str] = None,\n",
    "    patient_profiles: Sequence[str] = None,\n",
    "    scan_orders: Sequence[str] = None,\n",
    "    refined_profiles: Sequence[str] = None,\n",
    "    relevant_guidelines: Sequence[List[str]] = None,\n",
    "    query_engine: Optional[BaseQueryEngine] = None,\n",
    "    query_template: str = \"Patient Profile: {profile}\\nScan ordered: {scan_order}\",\n",
    "    text_qa_template: Optional[BasePromptTemplate] = None,\n",
    "    refine_template: Optional[LCChatPromptTemplate] = REFINE_TEMPLATE,\n",
    "    node_postprocessors: Optional[List[BaseNodePostprocessor]] = None,\n",
    "    artifact_dir: str = ARTIFACT_DIR,\n",
    "    emb_folder: str = EMB_DIR,\n",
    "):\n",
    "    save_folder = os.path.join(\n",
    "        artifact_dir, \"{}_{}_{}_{}_{}\".format(\n",
    "            exp_args[\"synthesizer_llm\"],\n",
    "            exp_args[\"chunk_size\"],\n",
    "            exp_args[\"chunk_overlap\"],\n",
    "            exp_args[\"description\"],\n",
    "            datetime.now().strftime(\"%d-%m-%Y-%H-%M\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    logger = get_experiment_logs(exp_args[\"description\"], log_folder=save_folder)\n",
    "    \n",
    "    if not query_engine:\n",
    "        token_counter = TokenCountingHandler(\n",
    "            tokenizer=tiktoken.encoding_for_model(exp_args[\"synthesizer_llm\"]).encode\n",
    "        )\n",
    "        callback_manager = CallbackManager([token_counter])\n",
    "        db_directory = os.path.join(\n",
    "            emb_folder, exp_args[\"vectorstore\"],\n",
    "            \"{}_{}_{}\".format(exp_args[\"emb_type\"], exp_args[\"chunk_size\"], exp_args[\"chunk_overlap\"])\n",
    "            )\n",
    "        \n",
    "        logger.info(f\"--------------------\\nLoading VectorDB from {db_directory}\")\n",
    "        query_engine = setup_query_engine(\n",
    "            db_directory,\n",
    "            emb_store_type=exp_args[\"vectorstore\"],\n",
    "            index_name=exp_args[\"index_name\"],\n",
    "            similarity_top_k=exp_args[\"similarity_top_k\"],\n",
    "            text_qa_template=text_qa_template,\n",
    "            synthesizer_llm = exp_args[\"synthesizer_llm\"],\n",
    "            synthesizer_temperature = exp_args[\"synthesizer_temperature\"],\n",
    "            synthesizer_max_tokens = exp_args[\"synthesizer_max_tokens\"],\n",
    "            response_mode = \"simple_summarize\",\n",
    "            node_postprocessors = node_postprocessors,\n",
    "            callback_manager = callback_manager\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        token_counter = query_engine.callback_manager.handlers[0]\n",
    "\n",
    "    logger.info(\n",
    "        \"-------------\\nExperiment settings:\\n{}\".format(\n",
    "            \"\\n\".join([f\"{k}:{v}\" for k, v in exp_args.items()])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    with open(os.path.join(save_folder, \"settings.yaml\"), \"w\") as f:\n",
    "        yaml.dump(exp_args, f)\n",
    "\n",
    "    responses = []\n",
    "    \n",
    "    logger.info(\n",
    "        \"-------------\\nQA PROMPT: {}\".format(convert_prompt_to_string(query_engine._response_synthesizer._text_qa_template))\n",
    "    )\n",
    "\n",
    "    logger.info(\n",
    "        \"------START RUNNING TEST CASES---------\"\n",
    "    )\n",
    "\n",
    "    if not (patient_profiles is not None and scan_orders is not None):\n",
    "        if not testcases:\n",
    "            testcases = testcase_df[\"Clinical File\"]\n",
    "        patient_profiles = [remove_final_sentence(testcase, True)[0] for testcase in testcases]\n",
    "        scan_orders = [remove_final_sentence(testcase, True)[1] for testcase in testcases]\n",
    "\n",
    "    if exp_args.get(\"refine_profile\") or exp_args.get(\"metadata_filter\"):\n",
    "        if not (refined_profiles and relevant_guidelines):\n",
    "            logger.info(\n",
    "                \"-------------\\nREFINE PROMPT: {}\".format(convert_prompt_to_string(refine_template))\n",
    "            )\n",
    "            \n",
    "            from langchain.callbacks import get_openai_callback\n",
    "            refine_chain = LLMChain(\n",
    "                llm=LCChatOpenAI(model_name=exp_args.get(\"refine_llm\", \"gpt-3.5-turbo-1106\"), temperature=0, max_tokens=512),\n",
    "                prompt=refine_template)\n",
    "            \n",
    "            with get_openai_callback() as cb:\n",
    "                refined_infos = [extract_guidelines(profile, refine_chain) for profile in tqdm(patient_profiles, total=len(patient_profiles))]\n",
    "            print(f\"Number of refined tokens: Prompt tokens = {cb.prompt_tokens}, Completion tokens = {cb.completion_tokens}\")\n",
    "    \n",
    "            refined_profiles = [refined_info[0] for refined_info in refined_infos]\n",
    "            relevant_guidelines = [refined_info[1] for refined_info in refined_infos]\n",
    "    \n",
    "    if exp_args.get(\"refine_profile\"):\n",
    "        patient_profiles = refined_profiles\n",
    "    \n",
    "    testcase_df[\"queries\"] = [query_wrapper(query_template, {\"profile\": patient_profile, \"scan_order\": scan_order})\n",
    "                 for patient_profile, scan_order in zip(patient_profiles, scan_orders)]\n",
    "        \n",
    "    metadata_filters = relevant_guidelines if exp_args.get(\"metadata_filter\") else [None] * len(testcase_df[\"queries\"])\n",
    "    \n",
    "    for query, metadata_filter in tqdm(zip(testcase_df[\"queries\"], metadata_filters), total=len(testcase_df[\"queries\"])):\n",
    "        input_query = {\"str_or_query_bundle\": query, \"table_filter\": metadata_filter, \"text_filter\": metadata_filter} if metadata_filter is not None else {\"str_or_query_bundle\": query}\n",
    "        response = query_engine.query(**input_query)\n",
    "        responses.append(response)\n",
    "    \n",
    "      \n",
    "    logger.info(\"--------------\\nTokens Consumption: Total: {}, Prompt: {}, Completion: {}, Embeddings: {}\"\n",
    "                .format(token_counter.total_llm_token_count,\n",
    "                        token_counter.prompt_llm_token_count,\n",
    "                        token_counter.completion_llm_token_count,\n",
    "                        token_counter.total_embedding_token_count))\n",
    "\n",
    "    logger.info(f\"----------\\nTest case Completed. Saving Artifacts into {save_folder}\")\n",
    "    json_responses = process_result_json(\n",
    "        testcase_df, responses=responses, save_path=os.path.join(save_folder, \"results.json\")\n",
    "        )\n",
    "\n",
    "    result_df = process_result_df(\n",
    "        testcase_df, json_responses, save_path=os.path.join(save_folder, \"result.csv\")\n",
    "        )\n",
    "\n",
    "    accuracy = result_df[\"match\"].sum() / len(result_df) * 100\n",
    "\n",
    "    logger.info(\"------EVALUATION-----\")\n",
    "    logger.info(f\"Accuracy score: {accuracy}\")\n",
    "    logger.info(\n",
    "        str(result_df.groupby([\"gpt_classification\", \"human_gt\"])[\"match\"].value_counts())\n",
    "    )\n",
    "    logger.info(\n",
    "        str(result_df.groupby([\"human_gt\", \"gpt_classification\"])[\"match\"].value_counts())\n",
    "    )\n",
    "\n",
    "    return json_responses, result_df, responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcase_df = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, \"queries\", \"MSK LLM Fictitious Case Files Full.csv\"),\n",
    "        usecols = ['ACR scenario', 'Appropriateness Category', 'Scan Order',\n",
    "                   'Difficulty', 'Clinical File']\n",
    "        )\n",
    "\n",
    "patient_profiles = [remove_final_sentence(patient_profile, True)[0].strip() for patient_profile in testcase_df[\"Clinical File\"]]\n",
    "scan_orders = [remove_final_sentence(patient_profile, True)[1].strip() for patient_profile in testcase_df[\"Clinical File\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of docs before filtering: 546\n",
      "Total number of docs after filtering 395\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(DOCUMENT_DIR).load_data()\n",
    "print(\"Total no of docs before filtering:\", len(documents))\n",
    "with open(EXCLUDE_DICT, \"r\") as f:\n",
    "    exclude_pages = json.load(f)\n",
    "documents = filter_by_pages(doc_list=documents, exclude_info=exclude_pages)\n",
    "print(\"Total number of docs after filtering\", len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Experiment (Rau et al 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp Settings Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Prompt\n",
    "CHAT_PROMPT_TEMPLATE = None\n",
    "\n",
    "rau_query_template = (\n",
    "    \"Case: {profile}\\n\"\n",
    "    \"Scan Ordered: {scan_order}\\n\"\n",
    "    \"Question: Is this imaging modality for this case USUALLY APPROPRIATE, \"\n",
    "    \"MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or INSUFFICIENT INFORMATION. \"\n",
    "    \"Then state precisely the most appropriate imaging modality and if contrast \"\n",
    "    \"agent is needed\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_args_baseline = dict(\n",
    "    # Retrieval \n",
    "    emb_type = \"openai\",\n",
    "    vectorstore = \"simple\",\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap = 20,\n",
    "    similarity_top_k = 3,\n",
    "    index_name = \"msk-mri\",\n",
    "    description=\"BaselineExperimentRau2023\",\n",
    "\n",
    "    # Generation\n",
    "    synthesizer_llm = \"gpt-4\",\n",
    "    synthesizer_max_tokens = 512,\n",
    "    synthesizer_temperature = 0,\n",
    "    response_mode = \"compact\",\n",
    ")\n",
    "\n",
    "token_counter = TokenCountingHandler(\n",
    "    tokenizer=tiktoken.encoding_for_model(\"gpt-3.5-turbo\").encode\n",
    ")\n",
    "callback_manager = CallbackManager([token_counter])\n",
    "\n",
    "text_qa_template = CHAT_PROMPT_TEMPLATE\n",
    "node_postprocessors = [LongContextReorder()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_responses, result_df, responses = run_test_cases(\n",
    "    testcase_df=testcase_df,\n",
    "    exp_args=exp_args_baseline,\n",
    "    patient_profiles=patient_profiles,\n",
    "    scan_orders=scan_orders,\n",
    "    query_template=rau_query_template,\n",
    "    text_qa_template=text_qa_template,\n",
    "    node_postprocessors=node_postprocessors\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Test Cases - Rau Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "rau_testcase_df = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, \"queries\", \"Rau Testcases.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-31 15:14:19,516:INFO: --------------------\n",
      "Loading VectorDB from /mnt/c/Users/QUAN/Desktop/lbp_mri/data/emb_store/simple/openai_512_20\n",
      "2023-10-31 15:14:19,516:INFO: --------------------\n",
      "Loading VectorDB from /mnt/c/Users/QUAN/Desktop/lbp_mri/data/emb_store/simple/openai_512_20\n",
      "2023-10-31 15:14:19,516:INFO: --------------------\n",
      "Loading VectorDB from /mnt/c/Users/QUAN/Desktop/lbp_mri/data/emb_store/simple/openai_512_20\n",
      "2023-10-31 15:14:19,516:INFO: --------------------\n",
      "Loading VectorDB from /mnt/c/Users/QUAN/Desktop/lbp_mri/data/emb_store/simple/openai_512_20\n",
      "2023-10-31 15:14:19,516:INFO: --------------------\n",
      "Loading VectorDB from /mnt/c/Users/QUAN/Desktop/lbp_mri/data/emb_store/simple/openai_512_20\n",
      "2023-10-31 15:14:19,516:INFO: --------------------\n",
      "Loading VectorDB from /mnt/c/Users/QUAN/Desktop/lbp_mri/data/emb_store/simple/openai_512_20\n",
      "2023-10-31 15:14:19,516:INFO: --------------------\n",
      "Loading VectorDB from /mnt/c/Users/QUAN/Desktop/lbp_mri/data/emb_store/simple/openai_512_20\n",
      "2023-10-31 15:14:19,516:INFO: --------------------\n",
      "Loading VectorDB from /mnt/c/Users/QUAN/Desktop/lbp_mri/data/emb_store/simple/openai_512_20\n",
      "2023-10-31 15:14:26,697:INFO: simple VectorStore successfully loaded from /mnt/c/Users/QUAN/Desktop/lbp_mri/data/emb_store/simple/openai_512_20.\n",
      "2023-10-31 15:14:26,700:INFO: -------------\n",
      "Experiment settings:\n",
      "emb_type:openai\n",
      "vectorstore:simple\n",
      "chunk_size:512\n",
      "chunk_overlap:20\n",
      "similarity_top_k:3\n",
      "index_name:msk-mri\n",
      "description:BaselineExperimentRau2023\n",
      "synthesizer_llm:gpt-4\n",
      "synthesizer_max_tokens:512\n",
      "synthesizer_temperature:0\n",
      "response_mode:compact\n",
      "2023-10-31 15:14:26,700:INFO: -------------\n",
      "Experiment settings:\n",
      "emb_type:openai\n",
      "vectorstore:simple\n",
      "chunk_size:512\n",
      "chunk_overlap:20\n",
      "similarity_top_k:3\n",
      "index_name:msk-mri\n",
      "description:BaselineExperimentRau2023\n",
      "synthesizer_llm:gpt-4\n",
      "synthesizer_max_tokens:512\n",
      "synthesizer_temperature:0\n",
      "response_mode:compact\n",
      "2023-10-31 15:14:26,700:INFO: -------------\n",
      "Experiment settings:\n",
      "emb_type:openai\n",
      "vectorstore:simple\n",
      "chunk_size:512\n",
      "chunk_overlap:20\n",
      "similarity_top_k:3\n",
      "index_name:msk-mri\n",
      "description:BaselineExperimentRau2023\n",
      "synthesizer_llm:gpt-4\n",
      "synthesizer_max_tokens:512\n",
      "synthesizer_temperature:0\n",
      "response_mode:compact\n",
      "2023-10-31 15:14:26,700:INFO: -------------\n",
      "Experiment settings:\n",
      "emb_type:openai\n",
      "vectorstore:simple\n",
      "chunk_size:512\n",
      "chunk_overlap:20\n",
      "similarity_top_k:3\n",
      "index_name:msk-mri\n",
      "description:BaselineExperimentRau2023\n",
      "synthesizer_llm:gpt-4\n",
      "synthesizer_max_tokens:512\n",
      "synthesizer_temperature:0\n",
      "response_mode:compact\n",
      "2023-10-31 15:14:26,700:INFO: -------------\n",
      "Experiment settings:\n",
      "emb_type:openai\n",
      "vectorstore:simple\n",
      "chunk_size:512\n",
      "chunk_overlap:20\n",
      "similarity_top_k:3\n",
      "index_name:msk-mri\n",
      "description:BaselineExperimentRau2023\n",
      "synthesizer_llm:gpt-4\n",
      "synthesizer_max_tokens:512\n",
      "synthesizer_temperature:0\n",
      "response_mode:compact\n",
      "2023-10-31 15:14:26,700:INFO: -------------\n",
      "Experiment settings:\n",
      "emb_type:openai\n",
      "vectorstore:simple\n",
      "chunk_size:512\n",
      "chunk_overlap:20\n",
      "similarity_top_k:3\n",
      "index_name:msk-mri\n",
      "description:BaselineExperimentRau2023\n",
      "synthesizer_llm:gpt-4\n",
      "synthesizer_max_tokens:512\n",
      "synthesizer_temperature:0\n",
      "response_mode:compact\n",
      "2023-10-31 15:14:26,700:INFO: -------------\n",
      "Experiment settings:\n",
      "emb_type:openai\n",
      "vectorstore:simple\n",
      "chunk_size:512\n",
      "chunk_overlap:20\n",
      "similarity_top_k:3\n",
      "index_name:msk-mri\n",
      "description:BaselineExperimentRau2023\n",
      "synthesizer_llm:gpt-4\n",
      "synthesizer_max_tokens:512\n",
      "synthesizer_temperature:0\n",
      "response_mode:compact\n",
      "2023-10-31 15:14:26,700:INFO: -------------\n",
      "Experiment settings:\n",
      "emb_type:openai\n",
      "vectorstore:simple\n",
      "chunk_size:512\n",
      "chunk_overlap:20\n",
      "similarity_top_k:3\n",
      "index_name:msk-mri\n",
      "description:BaselineExperimentRau2023\n",
      "synthesizer_llm:gpt-4\n",
      "synthesizer_max_tokens:512\n",
      "synthesizer_temperature:0\n",
      "response_mode:compact\n",
      "2023-10-31 15:14:26,718:INFO: -------------\n",
      "QA PROMPT: Context information is below.\n",
      "---------------------\n",
      "context_str\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: query_str\n",
      "Answer: \n",
      "2023-10-31 15:14:26,718:INFO: -------------\n",
      "QA PROMPT: Context information is below.\n",
      "---------------------\n",
      "context_str\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: query_str\n",
      "Answer: \n",
      "2023-10-31 15:14:26,718:INFO: -------------\n",
      "QA PROMPT: Context information is below.\n",
      "---------------------\n",
      "context_str\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: query_str\n",
      "Answer: \n",
      "2023-10-31 15:14:26,718:INFO: -------------\n",
      "QA PROMPT: Context information is below.\n",
      "---------------------\n",
      "context_str\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: query_str\n",
      "Answer: \n",
      "2023-10-31 15:14:26,718:INFO: -------------\n",
      "QA PROMPT: Context information is below.\n",
      "---------------------\n",
      "context_str\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: query_str\n",
      "Answer: \n",
      "2023-10-31 15:14:26,718:INFO: -------------\n",
      "QA PROMPT: Context information is below.\n",
      "---------------------\n",
      "context_str\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: query_str\n",
      "Answer: \n",
      "2023-10-31 15:14:26,718:INFO: -------------\n",
      "QA PROMPT: Context information is below.\n",
      "---------------------\n",
      "context_str\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: query_str\n",
      "Answer: \n",
      "2023-10-31 15:14:26,718:INFO: -------------\n",
      "QA PROMPT: Context information is below.\n",
      "---------------------\n",
      "context_str\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: query_str\n",
      "Answer: \n",
      "2023-10-31 15:14:26,730:INFO: ------START RUNNING TEST CASES---------\n",
      "2023-10-31 15:14:26,730:INFO: ------START RUNNING TEST CASES---------\n",
      "2023-10-31 15:14:26,730:INFO: ------START RUNNING TEST CASES---------\n",
      "2023-10-31 15:14:26,730:INFO: ------START RUNNING TEST CASES---------\n",
      "2023-10-31 15:14:26,730:INFO: ------START RUNNING TEST CASES---------\n",
      "2023-10-31 15:14:26,730:INFO: ------START RUNNING TEST CASES---------\n",
      "2023-10-31 15:14:26,730:INFO: ------START RUNNING TEST CASES---------\n",
      "2023-10-31 15:14:26,730:INFO: ------START RUNNING TEST CASES---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'str_or_query_bundle': 'Case: Patient age: 68 Sex: Male. Chief complaint: Severe pain in the left hip after a fall. The patient fell down from the stairs while carrying groceries. He has a history of osteoporosis and takes medication for high blood pressure. The patient is unable to bear weight on the left leg and has severe pain in the left hip. There is no visible deformity, but there is tenderness in the left hip region. \\nScan Ordered: X-ray pelvis and left hip\\nQuestion: Is this imaging modality for this case USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or INSUFFICIENT INFORMATION. Then state precisely the most appropriate imaging modality and if contrast agent is needed'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1/16 [00:23<05:45, 23.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'str_or_query_bundle': 'Case: Patient age: 68 Sex: Male. Chief complaint: Severe pain in the left hip after a fall. The patient fell down from the stairs while carrying groceries. He has a history of osteoporosis and takes medication for high blood pressure. The patient is unable to bear weight on the left leg and has severe pain in the left hip. There is no visible deformity, but there is tenderness in the left hip region. \\nScan Ordered: MRI pelvis and left hip without and with IV contrast\\nQuestion: Is this imaging modality for this case USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or INSUFFICIENT INFORMATION. Then state precisely the most appropriate imaging modality and if contrast agent is needed'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 2/16 [00:41<04:43, 20.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'str_or_query_bundle': 'Case: Patient age: 30 years old Sex: Male. Chief Complaint: Sharp pain and swelling in the knee after a fall. The patient fell while playing football and landed on his left knee. He experienced immediate pain and swelling. He tried to put weight on the leg but was unable to do so due to the pain. The left knee was swollen and tender to the touch. There was limited range of motion due to pain. No visible deformity was noted. The patient was unable to bear weight on the left leg. Anterior drawer test positive. Radiographs revealed tibial plateau fracture. \\nScan Ordered: MRI left knee without IV Contrast\\nQuestion: Is this imaging modality for this case USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or INSUFFICIENT INFORMATION. Then state precisely the most appropriate imaging modality and if contrast agent is needed'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3/16 [00:54<03:41, 17.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'str_or_query_bundle': 'Case: Patient age: 30 years old Sex: Male. Chief Complaint: Sharp pain and swelling in the knee after a fall. The patient fell while playing football and landed on his left knee. He experienced immediate pain and swelling. He tried to put weight on the leg but was unable to do so due to the pain. The left knee was swollen and tender to the touch. There was limited range of motion due to pain. No visible deformity was noted. The patient was unable to bear weight on the left leg. Anterior drawer test positive. Radiographs revealed tibial plateau fracture. \\nScan Ordered: MRI left knee without and with IV Contrast\\nQuestion: Is this imaging modality for this case USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or INSUFFICIENT INFORMATION. Then state precisely the most appropriate imaging modality and if contrast agent is needed'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 4/16 [01:08<03:09, 15.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'str_or_query_bundle': 'Case: Patient age: 45 years old Sex: Male. Chief Complaint: Chronic pain in the elbow, worsened with use and not relieved with rest or over-the-counter pain medications. The patient works as a carpenter and has been experiencing elbow pain for the past six months. He has tried rest, cooling, and nonsteroidal anti-inflammatory drugs but has not found relief. He has no history of trauma or previous elbow injuries. The patient has tenderness around the lateral epicondyle of the elbow and pain with resisted wrist extension. There is no swelling or deformity noted. \\nScan Ordered: X-ray elbow\\nQuestion: Is this imaging modality for this case USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or INSUFFICIENT INFORMATION. Then state precisely the most appropriate imaging modality and if contrast agent is needed'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 5/16 [01:22<02:47, 15.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'str_or_query_bundle': 'Case: Patient age: 45 years old Sex: Male. Chief Complaint: Chronic pain in the elbow, worsened with use and not relieved with rest or over-the-counter pain medications. The patient works as a carpenter and has been experiencing elbow pain for the past six months. He has tried rest, cooling, and nonsteroidal anti-inflammatory drugs but has not found relief. He has no history of trauma or previous elbow injuries. The patient has tenderness around the lateral epicondyle of the elbow and pain with resisted wrist extension. There is no swelling or deformity noted. \\nScan Ordered: MRI elbow without IV contrast\\nQuestion: Is this imaging modality for this case USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or INSUFFICIENT INFORMATION. Then state precisely the most appropriate imaging modality and if contrast agent is needed'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 6/16 [01:37<02:32, 15.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'str_or_query_bundle': 'Case: Patient age: 42 years old Sex: Female. Chief Complaint: Severe pain in the right heel, especially in the morning and after prolonged standing or walking. The patient has been experiencing the pain for the past six months. She has tried over-the-counter pain relievers and rest, but the pain persists. She is otherwise healthy and does not have a history of foot injuries or surgeries. Tenderness and swelling in the medial aspect of the right heel. Pain on dorsiflexion of the toes and resisted plantar flexion of the foot. No signs of redness, warmth, or skin changes. Radiograph did not show a calcaneal spur or other osseous lesions\\nScan Ordered: MRI right foot without IV contrast\\nQuestion: Is this imaging modality for this case USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or INSUFFICIENT INFORMATION. Then state precisely the most appropriate imaging modality and if contrast agent is needed'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 7/16 [01:53<02:17, 15.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'str_or_query_bundle': 'Case: Patient age: 42 years old Sex: Female. Chief Complaint: Severe pain in the right heel, especially in the morning and after prolonged standing or walking. The patient has been experiencing the pain for the past six months. She has tried over-the-counter pain relievers and rest, but the pain persists. She is otherwise healthy and does not have a history of foot injuries or surgeries. Tenderness and swelling in the medial aspect of the right heel. Pain on dorsiflexion of the toes and resisted plantar flexion of the foot. No signs of redness, warmth, or skin changes. Radiograph did not show a calcaneal spur or other osseous lesions\\nScan Ordered: MRI right foot without and with IV contrast\\nQuestion: Is this imaging modality for this case USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or INSUFFICIENT INFORMATION. Then state precisely the most appropriate imaging modality and if contrast agent is needed'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 8/16 [02:04<01:50, 13.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'str_or_query_bundle': 'Case: Patient age: 30 years old Sex: Female. Chief Complaint: Low back pain, stiffness, and limited mobility that has been ongoing for the past 6 months. The patient reports that her symptoms started gradually and have been progressively worsening over time. She mentions that the pain is worse in the morning and improves throughout the day with activity. She denies any prior history of trauma, fever, or weight loss. She has a family history of spondyloarthritis. On examination, the patient has limited lumbar spine mobility, especially in extension. She also has no signs of swelling, erythema, or warmth. No neurological deficits are present. MRI of the sacroiliac joints was negative for spondyloarthritis. \\nScan Ordered: MRI lumbar spine without and with IV contrast\\nQuestion: Is this imaging modality for this case USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or INSUFFICIENT INFORMATION. Then state precisely the most appropriate imaging modality and if contrast agent is needed'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 9/16 [02:18<01:37, 13.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'str_or_query_bundle': 'Case: Patient age: 30 years old Sex: Female. Chief Complaint: Low back pain, stiffness, and limited mobility that has been ongoing for the past 6 months. The patient reports that her symptoms started gradually and have been progressively worsening over time. She mentions that the pain is worse in the morning and improves throughout the day with activity. She denies any prior history of trauma, fever, or weight loss. She has a family history of spondyloarthritis. On examination, the patient has limited lumbar spine mobility, especially in extension. She also has no signs of swelling, erythema, or warmth. No neurological deficits are present. MRI of the sacroiliac joints was negative for spondyloarthritis. \\nScan Ordered: US lumbar spine\\nQuestion: Is this imaging modality for this case USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or INSUFFICIENT INFORMATION. Then state precisely the most appropriate imaging modality and if contrast agent is needed'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 10/16 [02:36<01:31, 15.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'str_or_query_bundle': 'Case: Patient age: 55 years old Sex: Male. Chief Complaint: Difficulty in walking, numbness in lower extremities, and progressive weakness in legs for the past year. The patient reports a history of chronic lower back pain for the past 10 years, managed with nonsteroidal anti-inflammatory drugs and physical therapy. He denies any recent trauma or injury to the spine. However, he reports a gradual onset of difficulty in walking, especially on uneven surfaces, and numbness in his lower extremities for the past year. The patient also complains of progressive weakness in his legs, making it difficult to climb stairs and stand for extended periods. On examination, there is a decreased sensation to light touch and pinprick in both legs, worse on the right side. There is also bilateral weakness in hip flexion, knee extension, and ankle dorsiflexion, worse on the right side. Deep tendon reflexes are brisk in both legs, with upgoing plantar reflexes bilaterally.\\nScan Ordered: MRI lumbar spine without IV contrast\\nQuestion: Is this imaging modality for this case USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or INSUFFICIENT INFORMATION. Then state precisely the most appropriate imaging modality and if contrast agent is needed'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 11/16 [02:52<01:17, 15.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'str_or_query_bundle': 'Case: Patient age: 55 years old Sex: Male. Chief Complaint: Difficulty in walking, numbness in lower extremities, and progressive weakness in legs for the past year. The patient reports a history of chronic lower back pain for the past 10 years, managed with nonsteroidal anti-inflammatory drugs and physical therapy. He denies any recent trauma or injury to the spine. However, he reports a gradual onset of difficulty in walking, especially on uneven surfaces, and numbness in his lower extremities for the past year. The patient also complains of progressive weakness in his legs, making it difficult to climb stairs and stand for extended periods. On examination, there is a decreased sensation to light touch and pinprick in both legs, worse on the right side. There is also bilateral weakness in hip flexion, knee extension, and ankle dorsiflexion, worse on the right side. Deep tendon reflexes are brisk in both legs, with upgoing plantar reflexes bilaterally.\\nScan Ordered: MRI lumbar spine with IV contrast\\nQuestion: Is this imaging modality for this case USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or INSUFFICIENT INFORMATION. Then state precisely the most appropriate imaging modality and if contrast agent is needed'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 12/16 [03:11<01:05, 16.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'str_or_query_bundle': 'Case: Patient age: 55 years old Sex: Male. Chief Complaint: Difficulty in walking, numbness in lower extremities, and progressive weakness in legs for the past year. The patient reports a history of chronic lower back pain for the past 10 years, managed with nonsteroidal anti-inflammatory drugs and physical therapy. He denies any recent trauma or injury to the spine. However, he reports a gradual onset of difficulty in walking, especially on uneven surfaces, and numbness in his lower extremities for the past year. The patient also complains of progressive weakness in his legs, making it difficult to climb stairs and stand for extended periods. On examination, there is a decreased sensation to light touch and pinprick in both legs, worse on the right side. There is also bilateral weakness in hip flexion, knee extension, and ankle dorsiflexion, worse on the right side. Deep tendon reflexes are brisk in both legs, with upgoing plantar reflexes bilaterally.\\nScan Ordered: X-ray lumbar spine\\nQuestion: Is this imaging modality for this case USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or INSUFFICIENT INFORMATION. Then state precisely the most appropriate imaging modality and if contrast agent is needed'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 13/16 [03:29<00:50, 16.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'str_or_query_bundle': 'Case: Patient age: 43 years Sex: Female. Chief Complaint: Severe lower back pain and fever. The patient had undergone lumbar spine surgery with spondylodesis two weeks ago due to a herniated disc. She had experienced mild pain and discomfort after surgery, but her condition worsened with time. She also had a history of diabetes and hypertension. The patient had tenderness and swelling in the lower back, limited range of motion, and fever (39°C). There were no signs of neurological deficits. Blood tests reveal elevated ESR and CRP levels. \\nScan Ordered: MRI lumbar spine without and with IV contrast\\nQuestion: Is this imaging modality for this case USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or INSUFFICIENT INFORMATION. Then state precisely the most appropriate imaging modality and if contrast agent is needed'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 14/16 [03:58<00:41, 20.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'str_or_query_bundle': 'Case: Patient age: 43 years Sex: Female. Chief Complaint: Severe lower back pain and fever. The patient had undergone lumbar spine surgery with spondylodesis two weeks ago due to a herniated disc. She had experienced mild pain and discomfort after surgery, but her condition worsened with time. She also had a history of diabetes and hypertension. The patient had tenderness and swelling in the lower back, limited range of motion, and fever (39°C). There were no signs of neurological deficits. Blood tests reveal elevated ESR and CRP levels. \\nScan Ordered: X-ray lumbar spine\\nQuestion: Is this imaging modality for this case USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or INSUFFICIENT INFORMATION. Then state precisely the most appropriate imaging modality and if contrast agent is needed'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 15/16 [04:12<00:18, 18.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'str_or_query_bundle': 'Case: Patient age: 43 years Sex: Female. Chief Complaint: Severe lower back pain and fever. The patient had undergone lumbar spine surgery with spondylodesis two weeks ago due to a herniated disc. She had experienced mild pain and discomfort after surgery, but her condition worsened with time. She also had a history of diabetes and hypertension. The patient had tenderness and swelling in the lower back, limited range of motion, and fever (39°C). There were no signs of neurological deficits. Blood tests reveal elevated ESR and CRP levels. \\nScan Ordered: MRI lumbar spine with IV contrast\\nQuestion: Is this imaging modality for this case USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or INSUFFICIENT INFORMATION. Then state precisely the most appropriate imaging modality and if contrast agent is needed'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [04:29<00:00, 16.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-31 15:18:56,566:INFO: --------------\n",
      "Tokens Consumption: Total: 25728, Prompt: 24087, Completion: 1641, Embeddings: []\n",
      "2023-10-31 15:18:56,566:INFO: --------------\n",
      "Tokens Consumption: Total: 25728, Prompt: 24087, Completion: 1641, Embeddings: []\n",
      "2023-10-31 15:18:56,566:INFO: --------------\n",
      "Tokens Consumption: Total: 25728, Prompt: 24087, Completion: 1641, Embeddings: []\n",
      "2023-10-31 15:18:56,566:INFO: --------------\n",
      "Tokens Consumption: Total: 25728, Prompt: 24087, Completion: 1641, Embeddings: []\n",
      "2023-10-31 15:18:56,566:INFO: --------------\n",
      "Tokens Consumption: Total: 25728, Prompt: 24087, Completion: 1641, Embeddings: []\n",
      "2023-10-31 15:18:56,566:INFO: --------------\n",
      "Tokens Consumption: Total: 25728, Prompt: 24087, Completion: 1641, Embeddings: []\n",
      "2023-10-31 15:18:56,566:INFO: --------------\n",
      "Tokens Consumption: Total: 25728, Prompt: 24087, Completion: 1641, Embeddings: []\n",
      "2023-10-31 15:18:56,566:INFO: --------------\n",
      "Tokens Consumption: Total: 25728, Prompt: 24087, Completion: 1641, Embeddings: []\n",
      "2023-10-31 15:18:56,577:INFO: ----------\n",
      "Test case Completed. Saving Artifacts into /mnt/c/Users/QUAN/Desktop/lbp_mri/artifacts/gpt-4_512_20_BaselineExperimentRau2023_31-10-2023-15-14\n",
      "2023-10-31 15:18:56,577:INFO: ----------\n",
      "Test case Completed. Saving Artifacts into /mnt/c/Users/QUAN/Desktop/lbp_mri/artifacts/gpt-4_512_20_BaselineExperimentRau2023_31-10-2023-15-14\n",
      "2023-10-31 15:18:56,577:INFO: ----------\n",
      "Test case Completed. Saving Artifacts into /mnt/c/Users/QUAN/Desktop/lbp_mri/artifacts/gpt-4_512_20_BaselineExperimentRau2023_31-10-2023-15-14\n",
      "2023-10-31 15:18:56,577:INFO: ----------\n",
      "Test case Completed. Saving Artifacts into /mnt/c/Users/QUAN/Desktop/lbp_mri/artifacts/gpt-4_512_20_BaselineExperimentRau2023_31-10-2023-15-14\n",
      "2023-10-31 15:18:56,577:INFO: ----------\n",
      "Test case Completed. Saving Artifacts into /mnt/c/Users/QUAN/Desktop/lbp_mri/artifacts/gpt-4_512_20_BaselineExperimentRau2023_31-10-2023-15-14\n",
      "2023-10-31 15:18:56,577:INFO: ----------\n",
      "Test case Completed. Saving Artifacts into /mnt/c/Users/QUAN/Desktop/lbp_mri/artifacts/gpt-4_512_20_BaselineExperimentRau2023_31-10-2023-15-14\n",
      "2023-10-31 15:18:56,577:INFO: ----------\n",
      "Test case Completed. Saving Artifacts into /mnt/c/Users/QUAN/Desktop/lbp_mri/artifacts/gpt-4_512_20_BaselineExperimentRau2023_31-10-2023-15-14\n",
      "2023-10-31 15:18:56,577:INFO: ----------\n",
      "Test case Completed. Saving Artifacts into /mnt/c/Users/QUAN/Desktop/lbp_mri/artifacts/gpt-4_512_20_BaselineExperimentRau2023_31-10-2023-15-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:22<00:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-31 15:19:19,077:INFO: ------EVALUATION-----\n",
      "2023-10-31 15:19:19,077:INFO: ------EVALUATION-----\n",
      "2023-10-31 15:19:19,077:INFO: ------EVALUATION-----\n",
      "2023-10-31 15:19:19,077:INFO: ------EVALUATION-----\n",
      "2023-10-31 15:19:19,077:INFO: ------EVALUATION-----\n",
      "2023-10-31 15:19:19,077:INFO: ------EVALUATION-----\n",
      "2023-10-31 15:19:19,077:INFO: ------EVALUATION-----\n",
      "2023-10-31 15:19:19,077:INFO: ------EVALUATION-----\n",
      "2023-10-31 15:19:19,086:INFO: Accuracy score: 68.75\n",
      "2023-10-31 15:19:19,086:INFO: Accuracy score: 68.75\n",
      "2023-10-31 15:19:19,086:INFO: Accuracy score: 68.75\n",
      "2023-10-31 15:19:19,086:INFO: Accuracy score: 68.75\n",
      "2023-10-31 15:19:19,086:INFO: Accuracy score: 68.75\n",
      "2023-10-31 15:19:19,086:INFO: Accuracy score: 68.75\n",
      "2023-10-31 15:19:19,086:INFO: Accuracy score: 68.75\n",
      "2023-10-31 15:19:19,086:INFO: Accuracy score: 68.75\n",
      "2023-10-31 15:19:19,097:INFO: gpt_classification       human_gt                 match\n",
      "MAY BE APPROPRIATE       USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY APPROPRIATE      MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      True     6\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY NOT APPROPRIATE  MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY NOT APPROPRIATE  True     5\n",
      "Name: match, dtype: int64\n",
      "2023-10-31 15:19:19,097:INFO: gpt_classification       human_gt                 match\n",
      "MAY BE APPROPRIATE       USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY APPROPRIATE      MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      True     6\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY NOT APPROPRIATE  MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY NOT APPROPRIATE  True     5\n",
      "Name: match, dtype: int64\n",
      "2023-10-31 15:19:19,097:INFO: gpt_classification       human_gt                 match\n",
      "MAY BE APPROPRIATE       USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY APPROPRIATE      MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      True     6\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY NOT APPROPRIATE  MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY NOT APPROPRIATE  True     5\n",
      "Name: match, dtype: int64\n",
      "2023-10-31 15:19:19,097:INFO: gpt_classification       human_gt                 match\n",
      "MAY BE APPROPRIATE       USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY APPROPRIATE      MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      True     6\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY NOT APPROPRIATE  MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY NOT APPROPRIATE  True     5\n",
      "Name: match, dtype: int64\n",
      "2023-10-31 15:19:19,097:INFO: gpt_classification       human_gt                 match\n",
      "MAY BE APPROPRIATE       USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY APPROPRIATE      MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      True     6\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY NOT APPROPRIATE  MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY NOT APPROPRIATE  True     5\n",
      "Name: match, dtype: int64\n",
      "2023-10-31 15:19:19,097:INFO: gpt_classification       human_gt                 match\n",
      "MAY BE APPROPRIATE       USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY APPROPRIATE      MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      True     6\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY NOT APPROPRIATE  MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY NOT APPROPRIATE  True     5\n",
      "Name: match, dtype: int64\n",
      "2023-10-31 15:19:19,097:INFO: gpt_classification       human_gt                 match\n",
      "MAY BE APPROPRIATE       USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY APPROPRIATE      MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      True     6\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY NOT APPROPRIATE  MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY NOT APPROPRIATE  True     5\n",
      "Name: match, dtype: int64\n",
      "2023-10-31 15:19:19,097:INFO: gpt_classification       human_gt                 match\n",
      "MAY BE APPROPRIATE       USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY APPROPRIATE      MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      True     6\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY NOT APPROPRIATE  MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY NOT APPROPRIATE  True     5\n",
      "Name: match, dtype: int64\n",
      "2023-10-31 15:19:19,106:INFO: human_gt                 gpt_classification       match\n",
      "MAY BE APPROPRIATE       USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY APPROPRIATE      MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      True     6\n",
      "USUALLY NOT APPROPRIATE  MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  True     5\n",
      "Name: match, dtype: int64\n",
      "2023-10-31 15:19:19,106:INFO: human_gt                 gpt_classification       match\n",
      "MAY BE APPROPRIATE       USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY APPROPRIATE      MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      True     6\n",
      "USUALLY NOT APPROPRIATE  MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  True     5\n",
      "Name: match, dtype: int64\n",
      "2023-10-31 15:19:19,106:INFO: human_gt                 gpt_classification       match\n",
      "MAY BE APPROPRIATE       USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY APPROPRIATE      MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      True     6\n",
      "USUALLY NOT APPROPRIATE  MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  True     5\n",
      "Name: match, dtype: int64\n",
      "2023-10-31 15:19:19,106:INFO: human_gt                 gpt_classification       match\n",
      "MAY BE APPROPRIATE       USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY APPROPRIATE      MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      True     6\n",
      "USUALLY NOT APPROPRIATE  MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  True     5\n",
      "Name: match, dtype: int64\n",
      "2023-10-31 15:19:19,106:INFO: human_gt                 gpt_classification       match\n",
      "MAY BE APPROPRIATE       USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY APPROPRIATE      MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      True     6\n",
      "USUALLY NOT APPROPRIATE  MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  True     5\n",
      "Name: match, dtype: int64\n",
      "2023-10-31 15:19:19,106:INFO: human_gt                 gpt_classification       match\n",
      "MAY BE APPROPRIATE       USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY APPROPRIATE      MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      True     6\n",
      "USUALLY NOT APPROPRIATE  MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  True     5\n",
      "Name: match, dtype: int64\n",
      "2023-10-31 15:19:19,106:INFO: human_gt                 gpt_classification       match\n",
      "MAY BE APPROPRIATE       USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY APPROPRIATE      MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      True     6\n",
      "USUALLY NOT APPROPRIATE  MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  True     5\n",
      "Name: match, dtype: int64\n",
      "2023-10-31 15:19:19,106:INFO: human_gt                 gpt_classification       match\n",
      "MAY BE APPROPRIATE       USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  False    1\n",
      "USUALLY APPROPRIATE      MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      True     6\n",
      "USUALLY NOT APPROPRIATE  MAY BE APPROPRIATE       False    1\n",
      "                         USUALLY APPROPRIATE      False    1\n",
      "                         USUALLY NOT APPROPRIATE  True     5\n",
      "Name: match, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rau_patient_profiles = rau_testcase_df[\"Patient Profiles\"]\n",
    "rau_scan_orders = rau_testcase_df[\"Scan Order\"]\n",
    "\n",
    "json_responses, result_df, responses = run_test_cases(\n",
    "    testcase_df=rau_testcase_df,\n",
    "    exp_args=exp_args_baseline,\n",
    "    patient_profiles=rau_patient_profiles,\n",
    "    scan_orders=rau_scan_orders,\n",
    "    query_template=rau_query_template,\n",
    "    text_qa_template=text_qa_template,\n",
    "    node_postprocessors=node_postprocessors\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run 0 - No RAG GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.prompts import PromptTemplate\n",
    "\n",
    "system_template = \"\"\"\n",
    "You are a radiologist expert at providing imaging recommendations for patients with musculoskeletal conditions.\n",
    "If you do not know an answer, just say \"I dont know\", do not make up an answer.\n",
    "==========\n",
    "TASK: You are given a PATIENT PROFILE and a SCAN ORDER. Your task is to evaluate the appropriateness of the SCAN ORDER based on the PATIENT PROFILE.\n",
    "Perform step-by-step the following sequence of reasoning.\n",
    "1. Extract from PATIENT PROFILE relevant information for classification of imaging appropriateness. DO NOT make any assumptions from the SCAN ORDER.\n",
    "Important information includes AGE, SYMPTOMS, PREVIOUS DIAGNOSIS (IF ANY), which stage of diagnosis (INITIAL IMAGING OR NEXT STUDY).\n",
    "2. Identify if there are superior imaging procedures or treatments with a more favorable risk-benefit ratio.\n",
    "3. Based on the SCORING CRITERIA, recommend if the SCAN ORDER is USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or there is INSUFFICIENT INFORMATION to recommend the appropriateness.  \n",
    "If the scan is not appropriate, recommend an appropriate procedure.\n",
    "==========\n",
    "SCORING CRITERIA:\n",
    "- USUALLY APPROPRIATE: The imaging procedure or treatment is indicated in the specified clinical scenarios at a favorable risk-benefit ratio for patients.\n",
    "- MAY BE APPROPRIATE: The imaging procedure or treatment may be indicated in the specified clinical scenarios as an alternative to imaging procedures or treatments with a more favorable risk-benefit ratio, or the risk-benefit ratio for patients is equivocal.\n",
    "- USUALLY NOT APPROPRIATE: The imaging procedure is unlikely to be recommended in the specified clinical scenarios, or the risk-benefit ratio for patients is likely to be unfavorable\n",
    "- INSUFFICIENT INFORMATION: The imaging procedure or treatment is not mentioned under CONTEXT or not enough relevant information from the PATIENT PROFILE to recommend based on information in CONTEXT.\n",
    "\n",
    "Take note for scenarios involving IV CONTRAST there are 3 distinct scan protocols: (1) with IV CONTRAST, (2) without IV CONTRAST, (3) without and with IV CONTRAST. \n",
    "Each of them is different and can have different appropriateness category.\n",
    "==========\n",
    "\"\"\"\n",
    "\n",
    "human_template = \"{query_str}\"\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(role=MessageRole.SYSTEM, content=system_template),\n",
    "    ChatMessage(role=MessageRole.USER, content=human_template)   \n",
    "]\n",
    "\n",
    "CHAT_PROMPT_TEMPLATE = ChatPromptTemplate(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llm_predictor import LLMPredictor\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "exp_args_0 = dict(\n",
    "    # Generation\n",
    "    description = \"NoRAG\",\n",
    "    synthesizer_llm = \"gpt-3.5-turbo-1106\",\n",
    "    synthesizer_max_tokens = 512,\n",
    "    synthesizer_temperature = 0,\n",
    ")\n",
    "\n",
    "text_qa_template = CHAT_PROMPT_TEMPLATE\n",
    "\n",
    "token_counter = TokenCountingHandler(\n",
    "    tokenizer=tiktoken.encoding_for_model(exp_args_0[\"synthesizer_llm\"]).encode\n",
    ")\n",
    "callback_manager = CallbackManager([token_counter])\n",
    "\n",
    "no_rag_llm = LLMPredictor(\n",
    "    llm=OpenAI(model=exp_args_0[\"synthesizer_llm\"], temperature=0, max_tokens=512),\n",
    "    callback_manager=callback_manager\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-03 18:59:40,432:INFO: -------------\n",
      "Experiment settings:\n",
      "description:NoRAG\n",
      "synthesizer_llm:gpt-4\n",
      "synthesizer_max_tokens:512\n",
      "synthesizer_temperature:0\n",
      "2023-11-03 18:59:40,438:INFO: -------------\n",
      "QA PROMPT: system: \n",
      "You are a radiologist expert at providing imaging recommendations for patients with musculoskeletal conditions.\n",
      "If you do not know an answer, just say \"I dont know\", do not make up an answer.\n",
      "==========\n",
      "TASK: You are given a PATIENT PROFILE and a SCAN ORDER. Your task is to evaluate the appropriateness of the SCAN ORDER based on the PATIENT PROFILE.\n",
      "Perform step-by-step the following sequence of reasoning.\n",
      "1. Extract from PATIENT PROFILE relevant information for classification of imaging appropriateness. DO NOT make any assumptions from the SCAN ORDER.\n",
      "Important information includes AGE, SYMPTOMS, PREVIOUS DIAGNOSIS (IF ANY), which stage of diagnosis (INITIAL IMAGING OR NEXT STUDY).\n",
      "2. Identify if there are superior imaging procedures or treatments with a more favorable risk-benefit ratio.\n",
      "3. Based on the SCORING CRITERIA, recommend if the SCAN ORDER is USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or there is INSUFFICIENT INFORMATION to recommend the appropriateness.  \n",
      "If the scan is not appropriate, recommend an appropriate procedure.\n",
      "==========\n",
      "SCORING CRITERIA:\n",
      "- USUALLY APPROPRIATE: The imaging procedure or treatment is indicated in the specified clinical scenarios at a favorable risk-benefit ratio for patients.\n",
      "- MAY BE APPROPRIATE: The imaging procedure or treatment may be indicated in the specified clinical scenarios as an alternative to imaging procedures or treatments with a more favorable risk-benefit ratio, or the risk-benefit ratio for patients is equivocal.\n",
      "- USUALLY NOT APPROPRIATE: The imaging procedure is unlikely to be recommended in the specified clinical scenarios, or the risk-benefit ratio for patients is likely to be unfavorable\n",
      "- INSUFFICIENT INFORMATION: The imaging procedure or treatment is not mentioned under CONTEXT or not enough relevant information from the PATIENT PROFILE to recommend based on information in CONTEXT.\n",
      "\n",
      "Take note for scenarios involving IV CONTRAST there are 3 distinct scan protocols: (1) with IV CONTRAST, (2) without IV CONTRAST, (3) without and with IV CONTRAST. \n",
      "Each of them is different and can have different appropriateness category.\n",
      "==========\n",
      "\n",
      "user: query_str\n",
      "assistant: \n",
      "2023-11-03 18:59:40,441:INFO: ------START RUNNING TEST CASES---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [36:23<00:00, 30.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-03 19:36:03,886:INFO: --------------\n",
      "Tokens Consumption: Total: 58510, Prompt: 39889, Completion: 18621, Embeddings: []\n",
      "2023-11-03 19:36:03,889:INFO: ----------\n",
      "Test case Completed. Saving Artifacts into /mnt/c/Users/QUAN/Desktop/lbp_mri/artifacts/gpt-4_NoRAG_03-11-2023-18-59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query_template = \"Patient Profile: {profile}\\nScan ordered: {scan_order}\"\n",
    "\n",
    "responses = []\n",
    "queries = []\n",
    "\n",
    "save_folder = os.path.join(\n",
    "    ARTIFACT_DIR, \"{}_{}_{}\".format(exp_args_0[\"synthesizer_llm\"], exp_args_0[\"description\"],\n",
    "                                    datetime.now().strftime(\"%d-%m-%Y-%H-%M\")))\n",
    "\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "logger = get_experiment_logs(exp_args_0[\"description\"], log_folder=save_folder)\n",
    "logger.info(\"-------------\\nExperiment settings:\\n{}\".format(\"\\n\".join([f\"{k}:{v}\" for k, v in exp_args_0.items()])))\n",
    "with open(os.path.join(save_folder, \"settings.yaml\"), \"w\") as f:\n",
    "    yaml.dump(exp_args_0, f)\n",
    "logger.info(\"-------------\\nQA PROMPT: {}\".format(convert_prompt_to_string(CHAT_PROMPT_TEMPLATE)))\n",
    "logger.info(\"------START RUNNING TEST CASES---------\")\n",
    "\n",
    "for patient_profile, scan_order in tqdm(zip(patient_profiles, scan_orders), total=len(patient_profiles)):\n",
    "    query_str = query_wrapper(query_template, {\"profile\": patient_profile, \"scan_order\": scan_order})\n",
    "    queries.append(query_str)\n",
    "    response = no_rag_llm.predict(text_qa_template, query_str=query_str)\n",
    "    responses.append(response)\n",
    "    \n",
    "token_counter = callback_manager.handlers[0]\n",
    "logger.info(\"--------------\\nTokens Consumption: Total: {}, Prompt: {}, Completion: {}, Embeddings: {}\"\n",
    "                .format(token_counter.total_llm_token_count,\n",
    "                        token_counter.prompt_llm_token_count,\n",
    "                        token_counter.completion_llm_token_count,\n",
    "                        token_counter.embedding_token_counts))\n",
    "\n",
    "logger.info(f\"----------\\nTest case Completed. Saving Artifacts into {save_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n"
     ]
    }
   ],
   "source": [
    "json_responses = []\n",
    "\n",
    "for query_str, response_str in zip(queries, responses):\n",
    "    testcase_info = {\"question\": query_str, \"result\": response_str}\n",
    "    answer_query = \"Scan Ordered: {}\\nAnswer: {}\".format(scan_order, testcase_info[\"result\"])\n",
    "    fixed_answer = fixing_chain(answer_query)\n",
    "    try:\n",
    "        appropriateness, recommendation = re.findall(\n",
    "        #  r\"^Appropriateness: ([0-9A-Za-z ]+)\\nRecommendation: ([0-9A-Za-z \\.]+)$\", fixed_answer[\"text\"])[0]\n",
    "            r\"^[^\\n]*Appropriateness: ([^\\n]+)\\n+[^\\n]*Recommendation: ([^\\n]+)$\", fixed_answer[\"text\"])[0]\n",
    "    except:\n",
    "        appropriateness, recommendation = \"\", \"\"\n",
    "        \n",
    "    testcase_info[\"appropriateness\"] = appropriateness\n",
    "    testcase_info[\"recommendation\"] = recommendation\n",
    "\n",
    "    json_responses.append(testcase_info)\n",
    "    \n",
    "with open(os.path.join(save_folder, \"results.json\"), \"w\") as f:\n",
    "    json.dump(json_responses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-03 19:47:46,423:INFO: ------EVALUATION-----\n",
      "2023-11-03 19:47:46,424:INFO: Accuracy score: 38.028169014084504\n",
      "2023-11-03 19:47:46,515:INFO: gpt_classification       human_gt                  match\n",
      "MAY BE APPROPRIATE       INSUFFICIENT INFORMATION  False     2\n",
      "                         MAY BE APPROPRIATE        True      3\n",
      "                         USUALLY APPROPRIATE       False     2\n",
      "                         USUALLY NOT APPROPRIATE   False    10\n",
      "USUALLY APPROPRIATE      INSUFFICIENT INFORMATION  False     8\n",
      "                         MAY BE APPROPRIATE        False    10\n",
      "                         USUALLY APPROPRIATE       True     17\n",
      "                         USUALLY NOT APPROPRIATE   False    10\n",
      "USUALLY NOT APPROPRIATE  MAY BE APPROPRIATE        False     1\n",
      "                         USUALLY APPROPRIATE       False     1\n",
      "                         USUALLY NOT APPROPRIATE   True      7\n",
      "Name: match, dtype: int64\n",
      "2023-11-03 19:47:46,517:INFO: human_gt                  gpt_classification       match\n",
      "INSUFFICIENT INFORMATION  MAY BE APPROPRIATE       False     2\n",
      "                          USUALLY APPROPRIATE      False     8\n",
      "MAY BE APPROPRIATE        MAY BE APPROPRIATE       True      3\n",
      "                          USUALLY APPROPRIATE      False    10\n",
      "                          USUALLY NOT APPROPRIATE  False     1\n",
      "USUALLY APPROPRIATE       MAY BE APPROPRIATE       False     2\n",
      "                          USUALLY APPROPRIATE      True     17\n",
      "                          USUALLY NOT APPROPRIATE  False     1\n",
      "USUALLY NOT APPROPRIATE   MAY BE APPROPRIATE       False    10\n",
      "                          USUALLY APPROPRIATE      False    10\n",
      "                          USUALLY NOT APPROPRIATE  True      7\n",
      "Name: match, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "result_df = deepcopy(testcase_df)\n",
    "\n",
    "result_df[\"gpt_raw_answer\"] = [response[\"result\"] for response in json_responses]\n",
    "result_df[\"gpt_classification\"] = [response[\"appropriateness\"] for response in json_responses]\n",
    "result_df[\"gpt_classification\"] = result_df[\"gpt_classification\"].str.upper()\n",
    "result_df[\"gpt_recommendation\"] = [response[\"recommendation\"] for response in json_responses]\n",
    "\n",
    "result_df = result_df.rename(columns = {\"Appropriateness Category\": \"human_gt\"})\n",
    "\n",
    "result_df[\"human_gt\"] = result_df[\"human_gt\"].str.replace(r\"^UA$\", \"USUALLY APPROPRIATE\", regex=True)\n",
    "result_df[\"human_gt\"] = result_df[\"human_gt\"].str.replace(r\"^UNA$\", \"USUALLY NOT APPROPRIATE\", regex=True)\n",
    "result_df[\"human_gt\"] = result_df[\"human_gt\"].str.replace(r\"^MBA$\", \"MAY BE APPROPRIATE\", regex=True)\n",
    "result_df[\"human_gt\"] = result_df[\"human_gt\"].str.replace(r\"^ICI$\", \"INSUFFICIENT INFORMATION\", regex=True)\n",
    "result_df[\"match\"] = (result_df[\"gpt_classification\"] == result_df[\"human_gt\"])\n",
    "\n",
    "result_df.to_csv(os.path.join(save_folder, \"result.csv\"))\n",
    "accuracy = result_df[\"match\"].sum() / len(result_df) * 100\n",
    "\n",
    "logger.info(\"------EVALUATION-----\")\n",
    "logger.info(f\"Accuracy score: {accuracy}\")\n",
    "logger.info(str(result_df.groupby([\"gpt_classification\", \"human_gt\"])[\"match\"].value_counts()))\n",
    "logger.info(str(result_df.groupby([\"human_gt\", \"gpt_classification\"])[\"match\"].value_counts()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run 1 - GPT-4, Chunk=512, Chunk_no=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp Settings Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "You are a radiologist expert at providing imaging recommendations for patients with musculoskeletal conditions.\n",
    "If you do not know an answer, just say \"I dont know\", do not make up an answer.\n",
    "==========\n",
    "TASK:\n",
    "1. Extract from given PATIENT PROFILE relevant information for classification of imaging appropriateness.\n",
    "Important information includes AGE, SYMPTOMS, DIAGNOSIS (IF ANY), which stage of diagnosis (INITIAL IMAGING OR NEXT STUDY).\n",
    "2. Refer to the reference information given under CONTEXT to analyse the appropriate imaging recommendations given the patient profile.\n",
    "3. Given the PATIENT PROFILE and CONTEXT, refer to the SCORING CRITERIA and recommend if the image scan ordered is USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or there is INSUFFICIENT INFORMATION to recommend the appropriateness.  \n",
    "If the scan is not appropriate, recommend an appropriate procedure.\n",
    "\n",
    "STRICTLY answer based on the given PATIENT PROFILE and CONTEXT. \n",
    "==========\n",
    "SCORING CRITERIA:\n",
    "- USUALLY APPROPRIATE: The imaging procedure or treatment is indicated in the specified clinical scenarios at a favorable risk-benefit ratio for patients.\n",
    "- MAY BE APPROPRIATE: The imaging procedure or treatment may be indicated in the specified clinical scenarios as an alternative to imaging procedures or treatments with a more favorable risk-benefit ratio, or the risk-benefit ratio for patients is equivocal.\n",
    "- USUALLY NOT APPROPRIATE: The imaging procedure or treatment is unlikely to be indicated in the specified clinical scenarios, or the risk-benefit ratio for patients is likely to be unfavorable.\n",
    "- INSUFFICIENT INFORMATION: There is not enough information from PATIENT PROFILE and CONTEXT information to conclude the appropriateness\n",
    "==========\n",
    "OUTPUT INSTRUCTIONS:\n",
    "Your output should contain the following:\n",
    "1. Classification of appropriateness for the ordered scan.\n",
    "2. Provide explanation for the appropriateness classification.\n",
    "3. If classification answer is USUALLY NOT APPROPRIATE, either recommend an alternative appropriate scan procedure or return NO SCAN REQUIRED.\n",
    "\n",
    "Format your output as follow:\n",
    "1. Classification: Can be one of [USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE, INSUFFICIENT INFORMATION]\n",
    "2. Explanation:\n",
    "3. Recommendation: Can be alternative procedure, NO SCAN REQUIRED or NO CHANGE REQUIRED \n",
    "==========\n",
    "CONTEXT:\n",
    "\n",
    "{context_str}\n",
    "==========\n",
    "\"\"\"\n",
    "\n",
    "human_template = \"{query_str}\"\n",
    "messages = [\n",
    "    ChatMessage(role=MessageRole.SYSTEM, content=system_template),\n",
    "    ChatMessage(role=MessageRole.USER, content=human_template)   \n",
    "]\n",
    "\n",
    "CHAT_PROMPT_TEMPLATE = ChatPromptTemplate(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_args_1 = dict(\n",
    "    # Retrieval \n",
    "    emb_type = \"openai\",\n",
    "    vectorstore = \"faiss\",\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap = 20,\n",
    "    similarity_top_k = 5,\n",
    "    index_name = \"msk-mri\",\n",
    "    description=\"Topk=5_RemoveFinalSentence\",\n",
    "\n",
    "    # Generation\n",
    "    synthesizer_llm = \"gpt-4\",\n",
    "    synthesizer_max_tokens = 512,\n",
    "    synthesizer_temperature = 0,\n",
    "    response_mode = \"simple_summarize\",\n",
    ")\n",
    "\n",
    "text_qa_template = CHAT_PROMPT_TEMPLATE\n",
    "node_postprocessors = [LongContextReorder()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_responses, result_df, responses = run_test_cases(\n",
    "    testcase_df=testcase_df,\n",
    "    exp_args=exp_args_1,\n",
    "    patient_profiles=patient_profiles,\n",
    "    scan_orders=scan_orders,\n",
    "    text_qa_template=text_qa_template,\n",
    "    node_postprocessors=node_postprocessors\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run 2 - GPT-4, Chunk=1024, Overlap=128 Chunk_no=7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp Settings Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import ChatMessage, MessageRole\n",
    "from llama_index.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"\"\"\n",
    "You are a radiologist expert at providing imaging recommendations for patients with musculoskeletal conditions.\n",
    "If you do not know an answer, just say \"I dont know\", do not make up an answer.\n",
    "==========\n",
    "TASK: \n",
    "1. Extract from given PATIENT PROFILE relevant information for classification of imaging appropriateness.\n",
    "Important information includes AGE, SYMPTOMS, DIAGNOSIS (IF ANY), which stage of diagnosis (INITIAL IMAGING OR NEXT STUDY).\n",
    "2. Refer to the reference information given under CONTEXT to analyse the appropriate imaging recommendations given the patient profile.\n",
    "3. Given the PATIENT PROFILE and CONTEXT, refer to the SCORING CRITERIA and recommend if the image scan ordered is USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or there is INSUFFICIENT INFORMATION to recommend the appropriateness.  \n",
    "If the scan is not appropriate, recommend an appropriate procedure.\n",
    "\n",
    "STRICTLY answer based on the given PATIENT PROFILE and CONTEXT. \n",
    "==========\n",
    "SCORING CRITERIA:\n",
    "- USUALLY APPROPRIATE: The imaging procedure or treatment is indicated in the specified clinical scenarios at a favorable risk-benefit ratio for patients.\n",
    "- MAY BE APPROPRIATE: The imaging procedure or treatment may be indicated in the specified clinical scenarios as an alternative to imaging procedures or treatments with a more favorable risk-benefit ratio, or the risk-benefit ratio for patients is equivocal.\n",
    "- USUALLY NOT APPROPRIATE: The imaging procedure or treatment is unlikely to be indicated in the specified clinical scenarios, or the risk-benefit ratio for patients is likely to be unfavorable.\n",
    "- INSUFFICIENT INFORMATION: There is not enough information from PATIENT PROFILE and CONTEXT information to conclude the appropriateness\n",
    "==========\n",
    "OUTPUT INSTRUCTIONS:\n",
    "Your output should contain the following:\n",
    "1. Classification of appropriateness for the ordered scan.\n",
    "2. Provide explanation for the appropriateness classification.\n",
    "3. If classification answer is USUALLY NOT APPROPRIATE, either recommend an alternative appropriate scan procedure or return NO SCAN REQUIRED.\n",
    "==========\n",
    "CONTEXT:\n",
    "\n",
    "{context_str}\n",
    "==========\n",
    "\"\"\"\n",
    "\n",
    "human_template = \"{query_str}\"\n",
    "messages = [\n",
    "    ChatMessage(role=MessageRole.SYSTEM, content=system_template),\n",
    "    ChatMessage(role=MessageRole.USER, content=human_template)   \n",
    "]\n",
    "\n",
    "CHAT_PROMPT_TEMPLATE = ChatPromptTemplate(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_args_2 = dict(\n",
    "    # Retrieval \n",
    "    emb_type = \"openai\",\n",
    "    vectorstore = \"faiss\",\n",
    "    chunk_size = 1024,\n",
    "    chunk_overlap = 128,\n",
    "    similarity_top_k = 7,\n",
    "    index_name = \"msk-mri\",\n",
    "    description=\"Topk=7_RemoveFinalSentence\",\n",
    "\n",
    "    # Generation\n",
    "    synthesizer_llm = \"gpt-4\",\n",
    "    synthesizer_max_tokens = 512,\n",
    "    synthesizer_temperature = 0,\n",
    "    response_mode = \"simple_summarize\",\n",
    ")\n",
    "\n",
    "text_qa_template = CHAT_PROMPT_TEMPLATE\n",
    "node_postprocessors = [LongContextReorder()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_responses, result_df, responses = run_test_cases(\n",
    "    testcase_df=testcase_df,\n",
    "    exp_args=exp_args_2,\n",
    "    patient_profiles=patient_profiles,\n",
    "    scan_orders=scan_orders,\n",
    "    text_qa_template=text_qa_template,\n",
    "    node_postprocessors=node_postprocessors\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run 3 - GPT-4, Chunk=512, Chunk_no=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp Settings Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import ChatMessage, MessageRole\n",
    "from llama_index.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"\"\"\n",
    "You are a radiologist expert at providing imaging recommendations for patients with musculoskeletal conditions.\n",
    "If you do not know an answer, just say \"I dont know\", do not make up an answer.\n",
    "==========\n",
    "TASK: You are given a PATIENT PROFILE and a SCAN ORDER. Your task is to evaluate the appropriateness of the SCAN ORDER based on the PATIENT PROFILE.\n",
    "Perform step-by-step the following sequence of reasoning.\n",
    "1. Extract from PATIENT PROFILE relevant information for classification of imaging appropriateness. DO NOT make any assumptions from the SCAN ORDER.\n",
    "Important information includes AGE, SYMPTOMS, PREVIOUS DIAGNOSIS (IF ANY), which stage of diagnosis (INITIAL IMAGING OR NEXT STUDY).\n",
    "2. Refer to the reference information given under CONTEXT to analyse the appropriate imaging recommendations given the patient profile.\n",
    "3. Identify there are superior imaging procedures or treatments with a more favorable risk-benefit ratio.\n",
    "4. Based on the SCORING CRITERIA, recommend if the SCAN ORDER is USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or there is INSUFFICIENT INFORMATION to recommend the appropriateness.  \n",
    "If the scan is not appropriate, recommend an appropriate procedure.\n",
    "\n",
    "STRICTLY answer based on the given PATIENT PROFILE and CONTEXT. \n",
    "==========\n",
    "SCORING CRITERIA:\n",
    "- USUALLY APPROPRIATE: The imaging procedure or treatment is indicated in the specified clinical scenarios at a favorable risk-benefit ratio for patients.\n",
    "- MAY BE APPROPRIATE: The imaging procedure or treatment may be indicated in the specified clinical scenarios as an alternative to imaging procedures or treatments with a more favorable risk-benefit ratio, or the risk-benefit ratio for patients is equivocal.\n",
    "- USUALLY NOT APPROPRIATE: The imaging procedure is unlikely to be recommended in the specified clinical scenarios, or the risk-benefit ratio for patients is likely to be unfavorable\n",
    "- INSUFFICIENT INFORMATION: The imaging procedure or treatment is not mentioned under CONTEXT or not enough relevant information from the PATIENT PROFILE to recommend based on information in CONTEXT.\n",
    "==========\n",
    "CONTEXT:\n",
    "\n",
    "{context_str}\n",
    "\n",
    "Take note for scenarios involving IV CONTRAST there are 3 distinct scan protocols: (1) with IV CONTRAST, (2) without IV CONTRAST, (3) without and with IV CONTRAST. \n",
    "Each of them is different and can have different appropriateness category.\n",
    "==========\n",
    "\"\"\"\n",
    "\n",
    "human_template = \"{query_str}\"\n",
    "messages = [\n",
    "    ChatMessage(role=MessageRole.SYSTEM, content=system_template),\n",
    "    ChatMessage(role=MessageRole.USER, content=human_template)   \n",
    "]\n",
    "\n",
    "CHAT_PROMPT_TEMPLATE = ChatPromptTemplate(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_args_3 = dict(\n",
    "    # Retrieval \n",
    "    emb_type = \"openai\",\n",
    "    vectorstore = \"faiss\",\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap = 20,\n",
    "    similarity_top_k = 5,\n",
    "    index_name = \"msk-mri\",\n",
    "    description=\"Topk=5_RemoveFinalSentence\",\n",
    "\n",
    "    # Generation\n",
    "    synthesizer_llm = \"gpt-3.5-turbo-1106\",\n",
    "    synthesizer_max_tokens = 512,\n",
    "    synthesizer_temperature = 0,\n",
    "    response_mode = \"simple_summarize\",\n",
    ")\n",
    "\n",
    "text_qa_template = CHAT_PROMPT_TEMPLATE\n",
    "node_postprocessors = [LongContextReorder()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_responses, result_df, responses = run_test_cases(\n",
    "    testcase_df=testcase_df,\n",
    "    exp_args=exp_args_3,\n",
    "    patient_profiles=patient_profiles,\n",
    "    scan_orders=scan_orders,\n",
    "    text_qa_template=text_qa_template,\n",
    "    node_postprocessors=node_postprocessors\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run 4 - Separate Tables and Text Vectorstores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp Settings Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "You are a radiologist expert at providing imaging recommendations for patients with musculoskeletal conditions.\n",
    "If you do not know an answer, just say \"I dont know\", do not make up an answer.\n",
    "==========\n",
    "TASK: You are given a PATIENT PROFILE and a SCAN ORDER. Your task is to evaluate the appropriateness of the SCAN ORDER based on the PATIENT PROFILE.\n",
    "Perform step-by-step the following sequence of reasoning.\n",
    "1. Extract from PATIENT PROFILE relevant information for classification of imaging appropriateness. DO NOT make any assumptions from the SCAN ORDER.\n",
    "Important information includes AGE, SYMPTOMS, PREVIOUS DIAGNOSIS (IF ANY), which stage of diagnosis (INITIAL IMAGING OR NEXT STUDY).\n",
    "2. Refer to the reference information given under CONTEXT to analyse the appropriate imaging recommendations given the patient profile.\n",
    "3. Identify there are superior imaging procedures or treatments with a more favorable risk-benefit ratio.\n",
    "4. Based on the SCORING CRITERIA, recommend if the SCAN ORDER is USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or there is INSUFFICIENT INFORMATION to recommend the appropriateness.  \n",
    "If the scan is not appropriate, recommend an appropriate procedure.\n",
    "\n",
    "STRICTLY answer based on the given PATIENT PROFILE and CONTEXT. \n",
    "==========\n",
    "SCORING CRITERIA:\n",
    "- USUALLY APPROPRIATE: The imaging procedure or treatment is indicated in the specified clinical scenarios at a favorable risk-benefit ratio for patients.\n",
    "- MAY BE APPROPRIATE: The imaging procedure or treatment may be indicated in the specified clinical scenarios as an alternative to imaging procedures or treatments with a more favorable risk-benefit ratio, or the risk-benefit ratio for patients is equivocal.\n",
    "- USUALLY NOT APPROPRIATE: The imaging procedure or treatment is unlikely to be indicated in the specified clinical scenarios, or the risk-benefit ratio for patients is likely to be unfavorable.\n",
    "- INSUFFICIENT INFORMATION: There is not enough information from PATIENT PROFILE and CONTEXT to give the recommendation\n",
    "==========\n",
    "CONTEXT:\n",
    "\n",
    "{context_str}\n",
    "\n",
    "Take note for scenarios involving IV CONTRAST there are 3 distinct scan protocols: (1) with IV CONTRAST, (2) without IV CONTRAST, (3) without and with IV CONTRAST. \n",
    "Each of them is different and can have different appropriateness category.\n",
    "==========\n",
    "\"\"\"\n",
    "\n",
    "human_template = \"{query_str}\"\n",
    "messages = [\n",
    "    ChatMessage(role=MessageRole.SYSTEM, content=system_template),\n",
    "    ChatMessage(role=MessageRole.USER, content=human_template)   \n",
    "]\n",
    "\n",
    "CHAT_PROMPT_TEMPLATE = ChatPromptTemplate(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_args = dict(\n",
    "    # Retrieval \n",
    "    emb_type = \"openai\",\n",
    "    vectorstore = \"faiss\",\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap = 20,\n",
    "    table_similarity_top_k = 4,\n",
    "    text_similarity_top_k = 5,\n",
    "    index_name = \"msk-mri\",\n",
    "    description=\"DescriptionsTableAndText\",\n",
    "\n",
    "    # Generation\n",
    "    synthesizer_llm = \"gpt-3.5-turbo\",\n",
    "    synthesizer_max_tokens = 512,\n",
    "    synthesizer_temperature = 0,\n",
    "    response_mode = \"simple_summarize\",\n",
    ")\n",
    "\n",
    "text_qa_template = CHAT_PROMPT_TEMPLATE\n",
    "# node_postprocessors = [LongContextReorder()]\n",
    "node_postprocessors = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-28 20:19:34,356:INFO: faiss VectorStore successfully loaded from /mnt/c/Users/QUAN/Desktop/lbp_mri/data/multimodal-faiss/descriptions/tables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-28 20:19:34,432:INFO: faiss VectorStore successfully loaded from /mnt/c/Users/QUAN/Desktop/lbp_mri/data/multimodal-faiss/descriptions/texts.\n"
     ]
    }
   ],
   "source": [
    "db_directory = os.path.join(DATA_DIR, \"multimodal-faiss\", \"descriptions\")\n",
    "table_index = load_vectorindex(os.path.join(db_directory, \"tables\"), \"faiss\")\n",
    "text_index = load_vectorindex(os.path.join(db_directory, \"texts\"), \"faiss\")\n",
    "\n",
    "table_retriever = table_index.as_retriever(\n",
    "    similarity_top_k = exp_args[\"table_similarity_top_k\"],\n",
    "    )\n",
    "text_retriever = text_index.as_retriever(\n",
    "    similarity_top_k = exp_args[\"text_similarity_top_k\"],\n",
    ")\n",
    "text_and_table_retriever = CustomCombinedRetriever(\n",
    "    table_retriever=table_retriever, text_retriever=text_retriever, token_limit = 7000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = OpenAIEmbedding()\n",
    "\n",
    "token_counter = TokenCountingHandler(\n",
    "    tokenizer=tiktoken.encoding_for_model(exp_args[\"synthesizer_llm\"]).encode\n",
    ")\n",
    "callback_manager = CallbackManager([token_counter])\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(\n",
    "        temperature=exp_args[\"synthesizer_temperature\"],\n",
    "        model=exp_args[\"synthesizer_llm\"], max_tokens=exp_args[\"synthesizer_max_tokens\"]\n",
    "        ),\n",
    "    embed_model=embs, callback_manager=callback_manager\n",
    ")\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    service_context=service_context, response_mode=exp_args[\"response_mode\"],\n",
    "    text_qa_template=CHAT_PROMPT_TEMPLATE\n",
    ")\n",
    "\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=text_and_table_retriever, response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors = node_postprocessors, callback_manager = CallbackManager([token_counter])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_responses, result_df, responses = run_test_cases(\n",
    "    testcase_df=testcase_df,\n",
    "    exp_args=exp_args,\n",
    "    patient_profiles=patient_profiles,\n",
    "    scan_orders=scan_orders,\n",
    "    query_engine=query_engine,\n",
    "    text_qa_template=text_qa_template,\n",
    "    node_postprocessors=node_postprocessors\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run 5 - Multisteps LLM Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and save first\n",
    "# multiple_guideline_answers = []\n",
    "# for clinical_file in tqdm(testcase_df[\"Clinical File\"],\n",
    "#                           total=len(testcase_df[\"Clinical File\"])):\n",
    "#     profile = remove_final_sentence(clinical_file)\n",
    "#     response = refine_chain(profile)\n",
    "#     multiple_guideline_answers.append(response[\"text\"])\n",
    "\n",
    "# profiles, guidelines = [], []\n",
    "\n",
    "# for answer in multiple_guideline_answers:\n",
    "#     if answer.endswith(\".\"):\n",
    "#         answer = answer[:-1]\n",
    "#     pattern = r\"1. Relevant information:([\\S\\s]+)2. Relevant guidelines:([\\S\\s]*)\"\n",
    "    \n",
    "#     profile, guidelines_str = re.findall(pattern, answer)[0]\n",
    "#     guidelines_str = guidelines_str.replace(\"- \", \"\")\n",
    "#     guidelines_str = guidelines_str.strip()\n",
    "#     guidelines_str = guidelines_str.replace(\"\\n\", \", \")\n",
    "    \n",
    "#     if not guidelines_str:\n",
    "#         profiles.append(profile)\n",
    "#         guidelines.append([])\n",
    "#     else:\n",
    "#         regex_guidelines = re.findall(r\"([A-Za-z ]+)\", guidelines_str)\n",
    "#         extracted_guidelines = []\n",
    "#         for i, extracted_guideline in enumerate(regex_guidelines):\n",
    "#             extracted_guideline = extracted_guideline.lower()\n",
    "#             min_dist, nearest_text = calculate_min_dist(extracted_guideline, GUIDELINES, True)\n",
    "#             if min_dist <= 1:\n",
    "#                 extracted_guideline = nearest_text\n",
    "#                 extracted_guidelines.append(extracted_guideline)\n",
    "#             else:\n",
    "#                 print(extracted_guideline + \"_\" + nearest_text)\n",
    "                \n",
    "#     profiles.append(profile.strip())   \n",
    "#     guidelines.append(extracted_guidelines)\n",
    "\n",
    "# extracted_info_multiple_json = {\"profiles\": profiles, \"guidelines\": guidelines}\n",
    "\n",
    "# with open(os.path.join(ARTIFACT_DIR, \"extracted_multiple.json\"), \"w\") as f:\n",
    "#     json.dump(extracted_info_multiple_json, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "You are a radiologist expert at providing imaging recommendations for patients with musculoskeletal conditions.\n",
    "If you do not know an answer, just say \"I dont know\", do not make up an answer.\n",
    "==========\n",
    "TASK: You are given a PATIENT PROFILE and a SCAN ORDER. Your task is to evaluate the appropriateness of the SCAN ORDER based on the PATIENT PROFILE.\n",
    "Perform step-by-step the following sequence of reasoning.\n",
    "1. Extract from PATIENT PROFILE relevant information for classification of imaging appropriateness. DO NOT make any assumptions from the SCAN ORDER.\n",
    "Important information includes AGE, SYMPTOMS, PREVIOUS DIAGNOSIS (IF ANY), which stage of diagnosis (INITIAL IMAGING OR NEXT STUDY).\n",
    "2. Refer to the reference information given under CONTEXT to analyse the appropriate imaging recommendations given the patient profile.\n",
    "3. Identify there are superior imaging procedures or treatments with a more favorable risk-benefit ratio.\n",
    "4. Based on the SCORING CRITERIA, recommend if the SCAN ORDER is USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or there is INSUFFICIENT INFORMATION to recommend the appropriateness.  \n",
    "If the scan is not appropriate, recommend an appropriate procedure.\n",
    "\n",
    "STRICTLY answer based on the given PATIENT PROFILE and CONTEXT. \n",
    "==========\n",
    "SCORING CRITERIA:\n",
    "- USUALLY APPROPRIATE: The imaging procedure or treatment is indicated in the specified clinical scenarios at a favorable risk-benefit ratio for patients.\n",
    "- MAY BE APPROPRIATE: The imaging procedure or treatment may be indicated in the specified clinical scenarios as an alternative to imaging procedures or treatments with a more favorable risk-benefit ratio, or the risk-benefit ratio for patients is equivocal.\n",
    "- USUALLY NOT APPROPRIATE: The imaging procedure is unlikely to be recommended in the specified clinical scenarios, or the risk-benefit ratio for patients is likely to be unfavorable\n",
    "- INSUFFICIENT INFORMATION: The imaging procedure or treatment is not mentioned under CONTEXT or not enough relevant information from the PATIENT PROFILE to recommend based on information in CONTEXT.\n",
    "==========\n",
    "CONTEXT:\n",
    "\n",
    "{context_str}\n",
    "\n",
    "Take note for scenarios involving IV CONTRAST there are 3 distinct scan protocols: (1) with IV CONTRAST, (2) without IV CONTRAST, (3) without and with IV CONTRAST. \n",
    "Each of them is different and can have different appropriateness category.\n",
    "==========\n",
    "\"\"\"\n",
    "\n",
    "human_template = \"{query_str}\"\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(role=MessageRole.SYSTEM, content=system_template),\n",
    "    ChatMessage(role=MessageRole.USER, content=human_template)   \n",
    "]\n",
    "\n",
    "CHAT_PROMPT_TEMPLATE = ChatPromptTemplate(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_args = dict(\n",
    "    # Retrieval \n",
    "    emb_type = \"openai\",\n",
    "    vectorstore = \"chroma\",\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap = 20,\n",
    "    table_similarity_top_k = 4,\n",
    "    text_similarity_top_k = 5,\n",
    "    index_name = \"msk-mri\",\n",
    "    description=\"DescriptionsTableAndTextWithMetadataFilter\",\n",
    "    metadata_filter = True,\n",
    "    refine_profile = False,\n",
    "    refine_llm = \"gpt-4-1106-preview\",\n",
    "\n",
    "    # Generation\n",
    "    synthesizer_llm = \"gpt-3.5-turbo-1106\",\n",
    "    synthesizer_max_tokens = 512,\n",
    "    synthesizer_temperature = 0,\n",
    "    response_mode = \"simple_summarize\",\n",
    ")\n",
    "\n",
    "text_qa_template = CHAT_PROMPT_TEMPLATE\n",
    "# node_postprocessors = [LongContextReorder()]\n",
    "node_postprocessors = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-25 13:20:11,955:INFO: chroma VectorStore successfully loaded from /mnt/c/Users/QUAN/Desktop/lbp_mri/data/multimodal-chroma/descriptions/tables.\n",
      "2023-11-25 13:20:12,090:INFO: chroma VectorStore successfully loaded from /mnt/c/Users/QUAN/Desktop/lbp_mri/data/multimodal-chroma/descriptions/texts.\n"
     ]
    }
   ],
   "source": [
    "db_directory = os.path.join(DATA_DIR, \"multimodal-chroma\", \"descriptions\")\n",
    "table_index = load_vectorindex(os.path.join(db_directory, \"tables\"), \"chroma\")\n",
    "text_index = load_vectorindex(os.path.join(db_directory, \"texts\"), \"chroma\")\n",
    "\n",
    "table_retriever = table_index.as_retriever(\n",
    "    similarity_top_k = exp_args[\"table_similarity_top_k\"]\n",
    "    )\n",
    "text_retriever = text_index.as_retriever(\n",
    "    similarity_top_k = exp_args[\"text_similarity_top_k\"]\n",
    ")\n",
    "text_and_table_retriever = CustomCombinedRetriever(\n",
    "    table_retriever=table_retriever, text_retriever=text_retriever, token_limit = 7000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = OpenAIEmbedding()\n",
    "\n",
    "token_counter = TokenCountingHandler(\n",
    "    tokenizer=tiktoken.encoding_for_model(exp_args[\"synthesizer_llm\"]).encode\n",
    ")\n",
    "callback_manager = CallbackManager([token_counter])\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(\n",
    "        temperature=exp_args[\"synthesizer_temperature\"],\n",
    "        model=exp_args[\"synthesizer_llm\"], max_tokens=exp_args[\"synthesizer_max_tokens\"]\n",
    "        ),\n",
    "    embed_model=embs, callback_manager=callback_manager\n",
    ")\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    service_context=service_context, response_mode=exp_args[\"response_mode\"],\n",
    "    text_qa_template=CHAT_PROMPT_TEMPLATE\n",
    ")\n",
    "\n",
    "query_engine = CustomRetrieverQueryEngine(\n",
    "    retriever=text_and_table_retriever, response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors = node_postprocessors, callback_manager = CallbackManager([token_counter])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(ARTIFACT_DIR, \"extracted_multiple.json\"), \"r\") as f:\n",
    "    extracted_infos = json.load(f)\n",
    "    \n",
    "refined_profiles = extracted_infos[\"profiles\"]\n",
    "relevant_guidelines = extracted_infos[\"guidelines\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_responses, result_df, responses = run_test_cases(\n",
    "    testcase_df=testcase_df,\n",
    "    exp_args=exp_args,\n",
    "    # patient_profiles=patient_profiles,\n",
    "    # scan_orders=scan_orders,\n",
    "    refined_profiles=refined_profiles,\n",
    "    relevant_guidelines=relevant_guidelines,\n",
    "    query_engine=query_engine,\n",
    "    text_qa_template=text_qa_template,\n",
    "    node_postprocessors=node_postprocessors\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Rau's Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "You are a radiologist expert at providing imaging recommendations for patients with musculoskeletal conditions.\n",
    "If you do not know an answer, just say \"I dont know\", do not make up an answer.\n",
    "==========\n",
    "TASK: You are given a PATIENT PROFILE and a SCAN ORDER. Your task is to evaluate the appropriateness of the SCAN ORDER based on the PATIENT PROFILE.\n",
    "Perform step-by-step the following sequence of reasoning.\n",
    "1. Extract from PATIENT PROFILE relevant information for classification of imaging appropriateness. DO NOT make any assumptions from the SCAN ORDER.\n",
    "Important information includes AGE, SYMPTOMS, PREVIOUS DIAGNOSIS (IF ANY), which stage of diagnosis (INITIAL IMAGING OR NEXT STUDY).\n",
    "2. Refer to the reference information given under CONTEXT to analyse the appropriate imaging recommendations given the patient profile.\n",
    "3. Identify there are superior imaging procedures or treatments with a more favorable risk-benefit ratio.\n",
    "4. Based on the SCORING CRITERIA, recommend if the SCAN ORDER is USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or there is INSUFFICIENT INFORMATION to recommend the appropriateness.  \n",
    "If the scan is not appropriate, recommend an appropriate procedure.\n",
    "\n",
    "STRICTLY answer based on the given PATIENT PROFILE and CONTEXT. \n",
    "==========\n",
    "SCORING CRITERIA:\n",
    "- USUALLY APPROPRIATE: The imaging procedure or treatment is indicated in the specified clinical scenarios at a favorable risk-benefit ratio for patients.\n",
    "- MAY BE APPROPRIATE: The imaging procedure or treatment may be indicated in the specified clinical scenarios as an alternative to imaging procedures or treatments with a more favorable risk-benefit ratio, or the risk-benefit ratio for patients is equivocal.\n",
    "- USUALLY NOT APPROPRIATE: The imaging procedure is unlikely to be recommended in the specified clinical scenarios, or the risk-benefit ratio for patients is likely to be unfavorable\n",
    "- INSUFFICIENT INFORMATION: The imaging procedure or treatment is not mentioned under CONTEXT or not enough relevant information from the PATIENT PROFILE to recommend based on information in CONTEXT.\n",
    "==========\n",
    "CONTEXT:\n",
    "\n",
    "{context_str}\n",
    "\n",
    "Take note for scenarios involving IV CONTRAST there are 3 distinct scan protocols: (1) with IV CONTRAST, (2) without IV CONTRAST, (3) without and with IV CONTRAST. \n",
    "Each of them is different and can have different appropriateness category.\n",
    "==========\n",
    "\"\"\"\n",
    "\n",
    "human_template = \"{query_str}\"\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(role=MessageRole.SYSTEM, content=system_template),\n",
    "    ChatMessage(role=MessageRole.USER, content=human_template)   \n",
    "]\n",
    "\n",
    "CHAT_PROMPT_TEMPLATE = ChatPromptTemplate(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_args = dict(\n",
    "    # Retrieval \n",
    "    emb_type = \"openai\",\n",
    "    vectorstore = \"chroma\",\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap = 20,\n",
    "    table_similarity_top_k = 4,\n",
    "    text_similarity_top_k = 5,\n",
    "    index_name = \"msk-mri\",\n",
    "    description=\"RauDataDescriptionsTableAndTextWithMetadataFilter\",\n",
    "    metadata_filter = True,\n",
    "    refine_profile = False,\n",
    "    refine_llm = \"gpt-4\",\n",
    "\n",
    "    # Generation\n",
    "    synthesizer_llm = \"gpt-4\",\n",
    "    synthesizer_max_tokens = 512,\n",
    "    synthesizer_temperature = 0,\n",
    "    response_mode = \"simple_summarize\",\n",
    ")\n",
    "\n",
    "text_qa_template = CHAT_PROMPT_TEMPLATE\n",
    "# node_postprocessors = [LongContextReorder()]\n",
    "node_postprocessors = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-31 14:11:34,295:INFO: chroma VectorStore successfully loaded from /mnt/c/Users/QUAN/Desktop/lbp_mri/data/multimodal-chroma/descriptions/tables.\n",
      "2023-10-31 14:11:34,450:INFO: chroma VectorStore successfully loaded from /mnt/c/Users/QUAN/Desktop/lbp_mri/data/multimodal-chroma/descriptions/texts.\n"
     ]
    }
   ],
   "source": [
    "db_directory = os.path.join(DATA_DIR, \"multimodal-chroma\", \"descriptions\")\n",
    "table_index = load_vectorindex(os.path.join(db_directory, \"tables\"), \"chroma\")\n",
    "text_index = load_vectorindex(os.path.join(db_directory, \"texts\"), \"chroma\")\n",
    "\n",
    "table_retriever = table_index.as_retriever(\n",
    "    similarity_top_k = exp_args[\"table_similarity_top_k\"]\n",
    "    )\n",
    "text_retriever = text_index.as_retriever(\n",
    "    similarity_top_k = exp_args[\"text_similarity_top_k\"]\n",
    ")\n",
    "text_and_table_retriever = CustomCombinedRetriever(\n",
    "    table_retriever=table_retriever, text_retriever=text_retriever, token_limit = 7000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = OpenAIEmbedding()\n",
    "\n",
    "token_counter = TokenCountingHandler(\n",
    "    tokenizer=tiktoken.encoding_for_model(exp_args[\"synthesizer_llm\"]).encode\n",
    ")\n",
    "callback_manager = CallbackManager([token_counter])\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(\n",
    "        temperature=exp_args[\"synthesizer_temperature\"],\n",
    "        model=exp_args[\"synthesizer_llm\"], max_tokens=exp_args[\"synthesizer_max_tokens\"]\n",
    "        ),\n",
    "    embed_model=embs, callback_manager=callback_manager\n",
    ")\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    service_context=service_context, response_mode=exp_args[\"response_mode\"],\n",
    "    text_qa_template=CHAT_PROMPT_TEMPLATE\n",
    ")\n",
    "\n",
    "query_engine = CustomRetrieverQueryEngine(\n",
    "    retriever=text_and_table_retriever, response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors = node_postprocessors, callback_manager = CallbackManager([token_counter])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rau_patient_profiles = rau_testcase_df[\"Patient Profiles\"]\n",
    "rau_scan_orders = rau_testcase_df[\"Scan Order\"]\n",
    "\n",
    "json_responses, result_df, responses = run_test_cases(\n",
    "    testcase_df=rau_testcase_df,\n",
    "    exp_args=exp_args,\n",
    "    patient_profiles=rau_patient_profiles,\n",
    "    scan_orders=rau_scan_orders,\n",
    "    query_engine=query_engine,\n",
    "    text_qa_template=text_qa_template,\n",
    "    node_postprocessors=node_postprocessors\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run 6: Table + Text (Node Sentence Window) + Metadata Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "You are a radiologist expert at providing imaging recommendations for patients with musculoskeletal conditions.\n",
    "If you do not know an answer, just say \"I dont know\", do not make up an answer.\n",
    "==========\n",
    "TASK: You are given a PATIENT PROFILE and a SCAN ORDER. Your task is to evaluate the appropriateness of the SCAN ORDER based on the PATIENT PROFILE.\n",
    "Perform step-by-step the following sequence of reasoning.\n",
    "1. Extract from PATIENT PROFILE relevant information for classification of imaging appropriateness. DO NOT make any assumptions from the SCAN ORDER.\n",
    "Important information includes AGE, SYMPTOMS, PREVIOUS DIAGNOSIS (IF ANY), which stage of diagnosis (INITIAL IMAGING OR NEXT STUDY).\n",
    "2. Refer to the reference information given under CONTEXT to analyse the appropriate imaging recommendations given the patient profile.\n",
    "3. Identify there are superior imaging procedures or treatments with a more favorable risk-benefit ratio.\n",
    "4. Based on the SCORING CRITERIA, recommend if the SCAN ORDER is USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE or there is INSUFFICIENT INFORMATION to recommend the appropriateness.  \n",
    "If the scan is not appropriate, recommend an appropriate procedure.\n",
    "\n",
    "STRICTLY answer based on the given PATIENT PROFILE and CONTEXT. \n",
    "==========\n",
    "SCORING CRITERIA:\n",
    "- USUALLY APPROPRIATE: The imaging procedure or treatment is indicated in the specified clinical scenarios at a favorable risk-benefit ratio for patients.\n",
    "- MAY BE APPROPRIATE: The imaging procedure or treatment may be indicated in the specified clinical scenarios as an alternative to imaging procedures or treatments with a more favorable risk-benefit ratio, or the risk-benefit ratio for patients is equivocal.\n",
    "- USUALLY NOT APPROPRIATE: The imaging procedure is unlikely to be recommended in the specified clinical scenarios, or the risk-benefit ratio for patients is likely to be unfavorable\n",
    "- INSUFFICIENT INFORMATION: The imaging procedure or treatment is not mentioned under CONTEXT or not enough relevant information from the PATIENT PROFILE to recommend based on information in CONTEXT.\n",
    "==========\n",
    "CONTEXT:\n",
    "\n",
    "{context_str}\n",
    "\n",
    "Take note for scenarios involving IV CONTRAST there are 3 distinct scan protocols: (1) with IV CONTRAST, (2) without IV CONTRAST, (3) without and with IV CONTRAST. \n",
    "Each of them is different and can have different appropriateness category.\n",
    "==========\n",
    "\"\"\"\n",
    "\n",
    "human_template = \"{query_str}\"\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(role=MessageRole.SYSTEM, content=system_template),\n",
    "    ChatMessage(role=MessageRole.USER, content=human_template)   \n",
    "]\n",
    "\n",
    "CHAT_PROMPT_TEMPLATE = ChatPromptTemplate(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_args = dict(\n",
    "    # Retrieval \n",
    "    emb_type = \"openai\",\n",
    "    vectorstore = \"chroma\",\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap = 20,\n",
    "    table_similarity_top_k = 4,\n",
    "    text_similarity_top_k = 5,\n",
    "    index_name = \"msk-mri\",\n",
    "    description=\"Descriptions-Table-TextSentenceWindow-WithMetadataFilter\",\n",
    "    metadata_filter = True,\n",
    "    refine_profile = False,\n",
    "    refine_llm = \"gpt-4-1106-preview\",\n",
    "    window = 5,\n",
    "\n",
    "    # Generation\n",
    "    synthesizer_llm = \"gpt-4-1106-preview\",\n",
    "    synthesizer_max_tokens = 512,\n",
    "    synthesizer_temperature = 0,\n",
    "    response_mode = \"simple_summarize\",\n",
    ")\n",
    "\n",
    "text_qa_template = CHAT_PROMPT_TEMPLATE\n",
    "node_postprocessors = [MetadataReplacementPostProcessor(target_metadata_key=\"window\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-10 20:12:52,056:INFO: chroma VectorStore successfully loaded from /mnt/c/Users/QUAN/Desktop/lbp_mri/data/multimodal-chroma-textwindow/descriptions/tables.\n",
      "2023-11-10 20:12:52,489:INFO: chroma VectorStore successfully loaded from /mnt/c/Users/QUAN/Desktop/lbp_mri/data/multimodal-chroma-textwindow/descriptions/texts.\n"
     ]
    }
   ],
   "source": [
    "db_directory = os.path.join(DATA_DIR, \"multimodal-chroma-textwindow\", \"descriptions\")\n",
    "table_index = load_vectorindex(\n",
    "    os.path.join(db_directory, \"tables\"),\n",
    "    emb_store_type=\"chroma\", index_name = \"tables\"\n",
    "    )\n",
    "text_index = load_vectorindex(\n",
    "    os.path.join(db_directory, \"texts\"),\n",
    "    emb_store_type=\"chroma\", index_name = \"texts\"\n",
    "    )\n",
    "\n",
    "table_retriever = table_index.as_retriever(\n",
    "    similarity_top_k = exp_args[\"table_similarity_top_k\"]\n",
    "    )\n",
    "text_retriever = text_index.as_retriever(\n",
    "    similarity_top_k = exp_args[\"text_similarity_top_k\"]\n",
    ")\n",
    "text_and_table_retriever = CustomCombinedRetriever(\n",
    "    table_retriever=table_retriever, text_retriever=text_retriever, token_limit = 7000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = OpenAIEmbedding()\n",
    "\n",
    "token_counter = TokenCountingHandler(\n",
    "    tokenizer=tiktoken.encoding_for_model(exp_args[\"synthesizer_llm\"]).encode\n",
    ")\n",
    "callback_manager = CallbackManager([token_counter])\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(\n",
    "        temperature=exp_args[\"synthesizer_temperature\"],\n",
    "        model=exp_args[\"synthesizer_llm\"], max_tokens=exp_args[\"synthesizer_max_tokens\"]\n",
    "        ),\n",
    "    embed_model=embs, callback_manager=callback_manager\n",
    ")\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    service_context=service_context, response_mode=exp_args[\"response_mode\"],\n",
    "    text_qa_template=CHAT_PROMPT_TEMPLATE\n",
    ")\n",
    "\n",
    "query_engine = CustomRetrieverQueryEngine(\n",
    "    retriever=text_and_table_retriever, response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors = node_postprocessors, callback_manager = CallbackManager([token_counter])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(ARTIFACT_DIR, \"extracted_multiple.json\"), \"r\") as f:\n",
    "    extracted_infos = json.load(f)\n",
    "    \n",
    "refined_profiles = extracted_infos[\"profiles\"]\n",
    "relevant_guidelines = extracted_infos[\"guidelines\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_responses, result_df, responses = run_test_cases(\n",
    "    testcase_df=testcase_df,\n",
    "    exp_args=exp_args,\n",
    "    refined_profiles=refined_profiles,\n",
    "    relevant_guidelines=relevant_guidelines,\n",
    "    query_engine=query_engine,\n",
    "    text_qa_template=text_qa_template,\n",
    "    node_postprocessors=node_postprocessors\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
