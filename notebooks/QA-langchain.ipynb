{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import re\n",
    "import sys\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from typing import Dict, List, Optional, Union\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_transformers import LongContextReorder\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document, BaseDocumentTransformer\n",
    "from langchain.callbacks.manager import CallbackManagerForChainRun\n",
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = \"..\"\n",
    "DATA_DIR = os.path.join(MAIN_DIR, \"data\")\n",
    "ARTIFACT_DIR = os.path.join(MAIN_DIR, \"artifacts\")\n",
    "DOCUMENTS_DIR = os.path.join(DATA_DIR, \"document_sources\")\n",
    "EMB_DIR = os.path.join(DATA_DIR, \"emb_store\")\n",
    "\n",
    "with open(os.path.join(MAIN_DIR, \"auth\", \"api_keys.json\"), \"r\") as f:\n",
    "    api_keys = json.load(f)\n",
    "    \n",
    "os.environ[\"OPENAI_API_KEY\"] = api_keys[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_prompt_to_string(prompt) -> str:\n",
    "    return prompt.format(**{v: v for v in prompt.input_variables})\n",
    "\n",
    "def generate_query(profile: str, scan: str):\n",
    "    return \"Patient Profile: {}\\nScan ordered: {}\".format(profile, scan)\n",
    "\n",
    "def convert_doc_to_dict(doc: Union[Document, Dict]) -> Dict:\n",
    "    if isinstance(doc, Document):\n",
    "        json_doc = {\n",
    "            \"page_content\": doc.page_content,\n",
    "            \"metadata\": {\n",
    "                \"source\": doc.metadata[\"source\"].split(\"/\")[-1],\n",
    "                \"page\": doc.metadata[\"page\"] + 1\n",
    "            }\n",
    "            }\n",
    "    elif isinstance(doc, Dict):\n",
    "        json_doc = {\n",
    "            \"page_content\": doc[\"page_content\"],\n",
    "            \"metadata\": {\n",
    "                \"source\": doc[\"metadata\"][\"source\"].split(\"/\")[-1],\n",
    "                \"page\": doc[\"metadata\"][\"page\"] + 1\n",
    "            }\n",
    "        }\n",
    "    return json_doc\n",
    "\n",
    "def get_experiment_logs(description: str, log_folder: str):\n",
    "    logger = logging.getLogger(description)\n",
    "\n",
    "    stream_handler = logging.StreamHandler(sys.stdout)\n",
    "\n",
    "    if not os.path.exists(log_folder):\n",
    "        os.makedirs(log_folder, exist_ok=True)\n",
    "\n",
    "    file_handler = logging.FileHandler(filename=os.path.join(log_folder, \"logfile.log\"))\n",
    "\n",
    "    formatter = logging.Formatter(\"%(asctime)s:%(levelname)s: %(message)s\")\n",
    "    file_handler.setFormatter(formatter)\n",
    "    stream_handler.setFormatter(formatter)\n",
    "\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.addHandler(stream_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    return logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0, max_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb_params = dict(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=128,\n",
    ")\n",
    "\n",
    "emb_db_path = os.path.join(EMB_DIR, \"faiss\",\n",
    "                           \"openai_{}_{}\".format(vectordb_params[\"chunk_size\"],\n",
    "                                                 vectordb_params[\"chunk_overlap\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create document stores\n",
    "# from langchain.document_loaders import PyPDFLoader\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# documents = os.listdir(DOCUMENTS_DIR)\n",
    "\n",
    "# texts = []\n",
    "\n",
    "# for document in documents:\n",
    "#     lbp_path = os.path.join(DOCUMENTS_DIR, document)\n",
    "#     docs = PyPDFLoader(lbp_path).load()\n",
    "#     print(\"Number of document pages:\", len(docs))\n",
    "#     text_splitter = RecursiveCharacterTextSplitter(**vectordb_params)\n",
    "#     texts.extend(text_splitter.split_documents(docs))\n",
    "\n",
    "# print(\"Number of text chunks:\", len(texts))\n",
    "\n",
    "# if not os.path.exists(emb_db_path):\n",
    "#     os.makedirs(emb_db_path, exist_ok=True)\n",
    "\n",
    "# docsearch = FAISS.from_documents(texts, embeddings)\n",
    "# docsearch.save_local(emb_db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = FAISS.load_local(emb_db_path, embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: \n",
      "You are a radiologist expert at providing imaging recommendations for patients with musculoskeletal conditions.\n",
      "If you do not know an answer, just say \"I dont know\", do not make up an answer.\n",
      "==========\n",
      "TASK:\n",
      "1. Extract from given PATIENT PROFILE relevant information for classification of imaging appropriateness.\n",
      "Important information includes AGE, SYMPTOMS, DIAGNOSIS (IF ANY), which stage of diagnosis (INITIAL IMAGING OR NEXT STUDY).\n",
      "2. Refer to the reference information given under CONTEXT to analyse the appropriate imaging recommendations given the patient profile.\n",
      "3. Recommend if the image scan ordered is appropriate given the PATIENT PROFILE and CONTEXT. If the scan is not appropriate, recommend an appropriate procedure.\n",
      "STRICTLY answer based on the given PATIENT PROFILE and CONTEXT.\n",
      "==========\n",
      "OUTPUT INSTRUCTIONS:\n",
      "Your output should contain the following:\n",
      "1. Classification of appropriateness for the ordered scan.\n",
      "2. Provide explanation for the appropriateness classification.\n",
      "3. If classification answer is USUALLY NOT APPROPRIATE, either recommend an alternative appropriate scan procedure or return NO SCAN REQUIRED.\n",
      "\n",
      "Format your output as follow:\n",
      "1. Classification: Can be one of [USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE, INSUFFICIENT INFORMATION]\n",
      "2. Explanation:\n",
      "3. Recommendation: Can be alternative procedure, NO SCAN REQUIRED or NO CHANGE REQUIRED \n",
      "==========\n",
      "CONTEXT:\n",
      "context\n",
      "==========\n",
      "\n",
      "Human: question\n"
     ]
    }
   ],
   "source": [
    "system_template = \"\"\"\n",
    "You are a radiologist expert at providing imaging recommendations for patients with musculoskeletal conditions.\n",
    "If you do not know an answer, just say \"I dont know\", do not make up an answer.\n",
    "==========\n",
    "TASK:\n",
    "1. Extract from given PATIENT PROFILE relevant information for classification of imaging appropriateness.\n",
    "Important information includes AGE, SYMPTOMS, DIAGNOSIS (IF ANY), which stage of diagnosis (INITIAL IMAGING OR NEXT STUDY).\n",
    "2. Refer to the reference information given under CONTEXT to analyse the appropriate imaging recommendations given the patient profile.\n",
    "3. Recommend if the image scan ordered is appropriate given the PATIENT PROFILE and CONTEXT. If the scan is not appropriate, recommend an appropriate procedure.\n",
    "STRICTLY answer based on the given PATIENT PROFILE and CONTEXT.\n",
    "==========\n",
    "OUTPUT INSTRUCTIONS:\n",
    "Your output should contain the following:\n",
    "1. Classification of appropriateness for the ordered scan.\n",
    "2. Provide explanation for the appropriateness classification.\n",
    "3. If classification answer is USUALLY NOT APPROPRIATE, either recommend an alternative appropriate scan procedure or return NO SCAN REQUIRED.\n",
    "\n",
    "Format your output as follow:\n",
    "1. Classification: Can be one of [USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE, INSUFFICIENT INFORMATION]\n",
    "2. Explanation:\n",
    "3. Recommendation: Can be alternative procedure, NO SCAN REQUIRED or NO CHANGE REQUIRED \n",
    "==========\n",
    "CONTEXT:\n",
    "{context}\n",
    "==========\n",
    "\"\"\"\n",
    "\n",
    "human_template = \"{question}\"\n",
    "\n",
    "PROMPT_TEMPLATE = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(system_template),\n",
    "        HumanMessagePromptTemplate.from_template(human_template)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(PROMPT_TEMPLATE.format(context=\"context\", question=\"question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReOrderQARetrieval(RetrievalQA):\n",
    "    \n",
    "    reorder_fn: Optional[BaseDocumentTransformer] = None\n",
    "    \n",
    "    def _get_docs(\n",
    "        self,\n",
    "        question: str,\n",
    "        *,\n",
    "        run_manager: CallbackManagerForChainRun,\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"Get docs.\"\"\"\n",
    "        docs = self.retriever.get_relevant_documents(\n",
    "            question, callbacks=run_manager.get_child()\n",
    "        )\n",
    "        \n",
    "        docs = self.reorder_fn.transform_documents(docs) if self.reorder_fn else docs\n",
    "     \n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = ReOrderQARetrieval.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=docsearch.as_retriever(search_kwargs={\"k\": 5}),\n",
    "    reorder_fn = LongContextReorder(),\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs=dict(\n",
    "        document_variable_name = \"context\",\n",
    "        prompt=PROMPT_TEMPLATE\n",
    "    ),\n",
    "    input_key=\"question\",\n",
    "    return_source_documents = True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-13 19:33:57,447:INFO: Experiment settings:\n",
      "llm_model:gpt=4\n",
      "emb_model:text-embeddings-ada-2\n",
      "framework:langchain\n",
      "prompt:System: \n",
      "You are a radiologist expert at providing imaging recommendations for patients with musculoskeletal conditions.\n",
      "If you do not know an answer, just say \"I dont know\", do not make up an answer.\n",
      "==========\n",
      "TASK:\n",
      "1. Extract from given PATIENT PROFILE relevant information for classification of imaging appropriateness.\n",
      "Important information includes AGE, SYMPTOMS, DIAGNOSIS (IF ANY), which stage of diagnosis (INITIAL IMAGING OR NEXT STUDY).\n",
      "2. Refer to the reference information given under CONTEXT to analyse the appropriate imaging recommendations given the patient profile.\n",
      "3. Recommend if the image scan ordered is appropriate given the PATIENT PROFILE and CONTEXT. If the scan is not appropriate, recommend an appropriate procedure.\n",
      "STRICTLY answer based on the given PATIENT PROFILE and CONTEXT.\n",
      "==========\n",
      "OUTPUT INSTRUCTIONS:\n",
      "Your output should contain the following:\n",
      "1. Classification of appropriateness for the ordered scan.\n",
      "2. Provide explanation for the appropriateness classification.\n",
      "3. If classification answer is USUALLY NOT APPROPRIATE, either recommend an alternative appropriate scan procedure or return NO SCAN REQUIRED.\n",
      "\n",
      "Format your output as follow:\n",
      "1. Classification: Can be one of [USUALLY APPROPRIATE, MAY BE APPROPRIATE, USUALLY NOT APPROPRIATE, INSUFFICIENT INFORMATION]\n",
      "2. Explanation:\n",
      "3. Recommendation: Can be alternative procedure, NO SCAN REQUIRED or NO CHANGE REQUIRED \n",
      "==========\n",
      "CONTEXT:\n",
      "context\n",
      "==========\n",
      "\n",
      "Human: question\n",
      "chunk_size:1024\n",
      "chunk_overlap:128\n",
      "description:RawVectorSearch\n",
      "max_tokens:512\n",
      "max_tokens_limit:default\n",
      "k:5\n",
      "chain_type:stuff\n"
     ]
    }
   ],
   "source": [
    "settings = dict(\n",
    "    llm_model=\"gpt=4\",\n",
    "    emb_model=\"text-embeddings-ada-2\",\n",
    "    framework=\"langchain\",\n",
    "    prompt=convert_prompt_to_string(PROMPT_TEMPLATE),\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=128,\n",
    "    description=\"RawVectorSearch\",\n",
    "    max_tokens=512,\n",
    "    max_tokens_limit=\"default\",\n",
    "    k=5,\n",
    "    chain_type=\"stuff\"\n",
    ")\n",
    "\n",
    "save_folder = os.path.join(\n",
    "    ARTIFACT_DIR,\n",
    "    \"{}_{}_{}_{}_{}\".format(\n",
    "        \"gpt-4\",\n",
    "        settings[\"chunk_size\"],\n",
    "        settings[\"chunk_overlap\"],\n",
    "        settings[\"description\"],\n",
    "        datetime.now().strftime(\"%d-%m-%Y-%H-%M\")\n",
    "    )\n",
    ")\n",
    "\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "LOGGER = get_experiment_logs(settings[\"description\"], log_folder=save_folder)\n",
    "LOGGER.info(\n",
    "    \"Experiment settings:\\n{}\".format(\n",
    "        \"\\n\".join([f\"{k}:{v}\" for k, v in settings.items()])\n",
    "    )\n",
    ")\n",
    "\n",
    "with open(os.path.join(save_folder, \"settings.yaml\"), \"w\") as f:\n",
    "    yaml.dump(settings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test cases: 71\n"
     ]
    }
   ],
   "source": [
    "testcase_df = pd.read_csv(os.path.join(DATA_DIR, \"queries\", \"MSK LLM Fictitious Case Files Full.csv\"))\n",
    "patient_profiles = testcase_df[\"Clinical File\"]\n",
    "scan_orders = testcase_df[\"MRI scan ordered\"]\n",
    "testcase_df[\"queries\"] = [generate_query(patient_profile, scan_order)\n",
    "        for patient_profile, scan_order in zip(patient_profiles, scan_orders)]\n",
    "\n",
    "LOGGER.info(f\"Number of test cases: {len(testcase_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "total_tokens, total_cost, prompt_tokens, completion_tokens = 0, 0, 0, 0\n",
    "\n",
    "for test_case in testcase_df[\"queries\"] :\n",
    "    with get_openai_callback() as cb:\n",
    "        response = qa_chain(test_case)\n",
    "    responses.append(response)\n",
    "    total_tokens += cb.total_tokens\n",
    "    total_cost += cb.total_cost\n",
    "    prompt_tokens += cb.prompt_tokens\n",
    "    completion_tokens += cb.completion_tokens\n",
    "    \n",
    "LOGGER.info(\"Tokens Consumption: Total: {}, Prompt: {}, Completion: {}\\nTotal Cost (USD): {}\"\n",
    "            .format(total_tokens, prompt_tokens, completion_tokens, total_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_responses = deepcopy(responses)\n",
    "\n",
    "for response in json_responses:\n",
    "    response[\"source_documents\"] = [convert_doc_to_dict(doc) for doc in response[\"source_documents\"]]\n",
    "\n",
    "with open(os.path.join(save_folder, \"results.json\"), \"w\") as f:\n",
    "    json.dump(json_responses, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_answers = []\n",
    "classifications = []\n",
    "recommendations = []\n",
    "retrieved_contexts = []\n",
    "\n",
    "for response in json_responses:\n",
    "    classification = re.search(r\"Classification: ([A-Z ]+)\\n\", response[\"result\"]).group(1)\n",
    "    recommendation = re.search(r\"Recommendation: (.+)$\", response[\"result\"]).group(1)\n",
    "    extracted_texts = [\n",
    "        \"- Source: {}, page {}\\n- Page Content: {}\".format(\n",
    "            doc[\"metadata\"][\"source\"], doc[\"metadata\"][\"page\"], doc[\"page_content\"])\n",
    "        for doc in response[\"source_documents\"]\n",
    "    ]\n",
    "    combined_texts = \"\\n\\n\".join(extracted_texts)    \n",
    "    \n",
    "    raw_answers.append(response[\"result\"])\n",
    "    classifications.append(classification)\n",
    "    recommendations.append(recommendation)\n",
    "    retrieved_contexts.append(combined_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = testcase_df[['Clinical File', 'MRI scan ordered',\n",
    "                        'Difficulty', 'queries', 'Appropriateness Category', ]]\n",
    "\n",
    "result_df = result_df.rename(columns = {\"Appropriateness Category\": \"human_gt\"})\n",
    "result_df[\"gpt_raw_answer\"] = raw_answers\n",
    "result_df[\"gpt4_classification\"] = classifications\n",
    "result_df[\"gpt4_recommendation\"] = recommendations\n",
    "result_df[\"retrieved_context\"] = retrieved_contexts\n",
    "result_df[\"human_gt\"] = result_df[\"human_gt\"].str.replace(r\"^UA$\", \"USUALLY APPROPRIATE\", regex=True)\n",
    "result_df[\"human_gt\"] = result_df[\"human_gt\"].str.replace(r\"^UNA$\", \"USUALLY NOT APPROPRIATE\", regex=True)\n",
    "result_df[\"human_gt\"] = result_df[\"human_gt\"].str.replace(r\"^MBA$\", \"MAY BE APPROPRIATE\", regex=True)\n",
    "result_df[\"human_gt\"] = result_df[\"human_gt\"].str.replace(r\"^ICI$\", \"INSUFFICIENT INFORMATION\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(os.path.join(save_folder, \"results.csv\"), header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
